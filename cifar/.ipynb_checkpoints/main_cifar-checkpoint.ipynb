{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from resnet20 import ResNetCIFAR\n",
    "from lenet import LeNet5\n",
    "from alexnet import AlexNet\n",
    "from train_util import train, test, train_gsm_unstructured, train_gsm_structured\n",
    "from summary import summary\n",
    "import torch\n",
    "import numpy as np\n",
    "from final_pruning import final_unstruct_pruning, final_struct_pruning\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchprofile import profile_macs\n",
    "from evaluate_util import compute_conv_flops\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based model ResNet-56 training with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = ResNetCIFAR(num_layers=56)\n",
    "net = net.to(device)\n",
    "\n",
    "# Comment if you have pretrained weights\n",
    "# train(net, epochs=EPOCHS, batch_size=128, lr=0.1, reg=1e-4, net_name = 'resnet_56_base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Test Loss=0.3370, Test accuracy=0.9312\n",
      "Layer id\tType\t\tParameter\tNon-zero parameter\tSparsity(\\%)\n",
      "1\t\tConvolutional_Param\t864\t\t864\t\t\t0.000000\n",
      "1\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "2\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "3\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "4\t\tConvolutional_Param\t4608\t\t4608\t\t\t0.000000\n",
      "4\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "5\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "6\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "7\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "7\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "8\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "9\t\tConvolutional_Param\t512\t\t512\t\t\t0.000000\n",
      "9\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "10\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "11\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "12\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "12\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "13\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "14\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "15\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "15\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "16\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "17\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "18\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "18\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "19\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "20\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "21\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "21\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "22\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "23\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "24\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "24\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "25\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "26\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "27\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "27\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "28\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "29\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "30\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "30\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "31\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "32\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "33\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "33\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "34\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "35\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "36\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "36\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "37\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "38\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "39\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "39\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "40\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "41\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "42\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "42\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "43\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "44\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "45\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "45\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "46\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "47\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "48\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "48\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "49\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "50\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "51\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "51\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "52\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "53\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "54\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "54\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "55\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "56\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "57\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "57\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "58\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "59\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "60\t\tConvolutional_Param\t4608\t\t4608\t\t\t0.000000\n",
      "60\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "61\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "62\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "63\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "63\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "64\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "65\t\tConvolutional_Param\t512\t\t512\t\t\t0.000000\n",
      "65\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "66\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "67\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "68\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "68\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "69\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "70\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "71\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "71\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "72\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "73\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "74\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "74\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "75\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "76\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "77\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "77\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "78\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "79\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "80\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "80\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "81\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "82\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "83\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "83\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "84\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "85\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "86\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "86\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "87\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "88\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "89\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "89\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "90\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "91\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "92\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "92\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "93\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "94\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "95\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "95\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "96\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "97\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "98\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "98\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "99\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "100\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "101\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "101\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "102\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "103\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "104\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "104\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "105\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "106\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "107\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "107\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "108\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "109\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "110\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "110\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "111\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "112\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "113\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "113\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "114\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "115\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "116\t\tConvolutional_Param\t18432\t\t18432\t\t\t0.000000\n",
      "116\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "117\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "118\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "119\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "119\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "120\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "121\t\tConvolutional_Param\t2048\t\t2048\t\t\t0.000000\n",
      "121\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "122\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "123\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "124\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "124\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "125\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "126\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "127\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "127\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "128\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "129\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "130\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "130\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "131\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "132\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "133\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "133\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "134\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "135\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "136\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "136\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "137\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "138\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "139\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "139\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "140\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "141\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "142\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "142\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "143\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "144\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "145\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "145\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "146\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "147\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "148\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "148\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "149\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "150\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "151\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "151\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "152\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "153\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "154\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "154\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "155\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "156\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "157\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "157\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "158\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "159\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "160\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "160\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "161\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "162\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "163\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "163\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "164\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "165\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "166\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "166\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "167\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "168\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "169\t\tConvolutional_Param\t36864\t\t36864\t\t\t0.000000\n",
      "169\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "170\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "171\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "172\t\tLinear\t\t640\t\t640\t\t\t0.000000\n",
      "172\t\ttLinear_Filter\t10\t\t10\t\t\t0.000000\n",
      "Total nonzero parameters: 854752\n",
      "Total parameters: 854752\n",
      "Total sparsity: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129073792.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"saved_models/resnet_56_base.pt\"))\n",
    "test(net)\n",
    "summary(net)\n",
    "compute_conv_flops(net, cuda=True, prune=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trained with Structured GSM SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ZERO_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n",
      "[Step=50]\tLoss=2.6674\tacc=0.1220\t1099.6 examples/second\n",
      "[Step=100]\tLoss=2.5845\tacc=0.1275\t1292.6 examples/second\n",
      "[Step=150]\tLoss=2.4998\tacc=0.1421\t1297.3 examples/second\n",
      "[Step=200]\tLoss=2.4191\tacc=0.1558\t1271.1 examples/second\n",
      "[Step=250]\tLoss=2.3580\tacc=0.1661\t1227.7 examples/second\n",
      "[Step=300]\tLoss=2.3108\tacc=0.1737\t1237.3 examples/second\n",
      "[Step=350]\tLoss=2.2739\tacc=0.1793\t1299.0 examples/second\n",
      "Test Loss=2.1173, Test acc=0.2056\n",
      "Saving...\n",
      "\n",
      "Epoch: 1\n",
      "[Step=400]\tLoss=1.9425\tacc=0.2431\t821.3 examples/second\n",
      "[Step=450]\tLoss=1.9113\tacc=0.2663\t1273.4 examples/second\n",
      "[Step=500]\tLoss=1.8956\tacc=0.2724\t1425.9 examples/second\n",
      "[Step=550]\tLoss=1.8833\tacc=0.2787\t1321.1 examples/second\n",
      "[Step=600]\tLoss=1.8655\tacc=0.2842\t1260.8 examples/second\n",
      "[Step=650]\tLoss=1.8499\tacc=0.2909\t1532.1 examples/second\n",
      "[Step=700]\tLoss=1.8340\tacc=0.2968\t1327.3 examples/second\n",
      "[Step=750]\tLoss=1.8163\tacc=0.3035\t1335.5 examples/second\n",
      "Test Loss=1.6731, Test acc=0.3697\n",
      "Saving...\n",
      "\n",
      "Epoch: 2\n",
      "[Step=800]\tLoss=1.6974\tacc=0.3407\t854.5 examples/second\n",
      "[Step=850]\tLoss=1.6741\tacc=0.3541\t1503.5 examples/second\n",
      "[Step=900]\tLoss=1.6628\tacc=0.3592\t1400.6 examples/second\n",
      "[Step=950]\tLoss=1.6515\tacc=0.3662\t1460.8 examples/second\n",
      "[Step=1000]\tLoss=1.6376\tacc=0.3713\t1311.4 examples/second\n",
      "[Step=1050]\tLoss=1.6251\tacc=0.3773\t1290.9 examples/second\n",
      "[Step=1100]\tLoss=1.6090\tacc=0.3835\t1339.0 examples/second\n",
      "[Step=1150]\tLoss=1.5971\tacc=0.3900\t1369.0 examples/second\n",
      "Test Loss=1.7395, Test acc=0.3967\n",
      "Saving...\n",
      "\n",
      "Epoch: 3\n",
      "[Step=1200]\tLoss=1.4628\tacc=0.4456\t886.1 examples/second\n",
      "[Step=1250]\tLoss=1.4652\tacc=0.4457\t1253.8 examples/second\n",
      "[Step=1300]\tLoss=1.4469\tacc=0.4571\t1313.6 examples/second\n",
      "[Step=1350]\tLoss=1.4193\tacc=0.4701\t1263.1 examples/second\n",
      "[Step=1400]\tLoss=1.4033\tacc=0.4794\t1342.5 examples/second\n",
      "[Step=1450]\tLoss=1.3851\tacc=0.4870\t1308.2 examples/second\n",
      "[Step=1500]\tLoss=1.3628\tacc=0.4951\t1271.0 examples/second\n",
      "[Step=1550]\tLoss=1.3439\tacc=0.5035\t1280.5 examples/second\n",
      "Test Loss=1.9029, Test acc=0.4782\n",
      "Saving...\n",
      "\n",
      "Epoch: 4\n",
      "[Step=1600]\tLoss=1.2043\tacc=0.5586\t866.4 examples/second\n",
      "[Step=1650]\tLoss=1.1906\tacc=0.5677\t1267.7 examples/second\n",
      "[Step=1700]\tLoss=1.1737\tacc=0.5782\t1308.9 examples/second\n",
      "[Step=1750]\tLoss=1.1638\tacc=0.5805\t1306.6 examples/second\n",
      "[Step=1800]\tLoss=1.1507\tacc=0.5847\t1385.9 examples/second\n",
      "[Step=1850]\tLoss=1.1415\tacc=0.5889\t1432.5 examples/second\n",
      "[Step=1900]\tLoss=1.1319\tacc=0.5921\t1436.7 examples/second\n",
      "[Step=1950]\tLoss=1.1224\tacc=0.5963\t1382.2 examples/second\n",
      "Test Loss=1.1468, Test acc=0.5881\n",
      "Saving...\n",
      "\n",
      "Epoch: 5\n",
      "[Step=2000]\tLoss=1.0559\tacc=0.6332\t874.9 examples/second\n",
      "[Step=2050]\tLoss=1.0360\tacc=0.6377\t1302.5 examples/second\n",
      "[Step=2100]\tLoss=1.0289\tacc=0.6363\t1271.1 examples/second\n",
      "[Step=2150]\tLoss=1.0245\tacc=0.6367\t1319.8 examples/second\n",
      "[Step=2200]\tLoss=1.0113\tacc=0.6403\t1339.7 examples/second\n",
      "[Step=2250]\tLoss=1.0081\tacc=0.6417\t1337.4 examples/second\n",
      "[Step=2300]\tLoss=0.9998\tacc=0.6443\t1299.7 examples/second\n",
      "Test Loss=1.0374, Test acc=0.6311\n",
      "Saving...\n",
      "\n",
      "Epoch: 6\n",
      "[Step=2350]\tLoss=0.9806\tacc=0.6680\t852.1 examples/second\n",
      "[Step=2400]\tLoss=0.9363\tacc=0.6675\t1367.8 examples/second\n",
      "[Step=2450]\tLoss=0.9578\tacc=0.6608\t1288.2 examples/second\n",
      "[Step=2500]\tLoss=0.9402\tacc=0.6653\t1363.8 examples/second\n",
      "[Step=2550]\tLoss=0.9346\tacc=0.6691\t1376.6 examples/second\n",
      "[Step=2600]\tLoss=0.9253\tacc=0.6734\t1477.3 examples/second\n",
      "[Step=2650]\tLoss=0.9210\tacc=0.6752\t1361.4 examples/second\n",
      "[Step=2700]\tLoss=0.9186\tacc=0.6764\t1319.6 examples/second\n",
      "Test Loss=1.0956, Test acc=0.6188\n",
      "\n",
      "Epoch: 7\n",
      "[Step=2750]\tLoss=0.8160\tacc=0.7073\t890.8 examples/second\n",
      "[Step=2800]\tLoss=0.8534\tacc=0.7028\t1445.8 examples/second\n",
      "[Step=2850]\tLoss=0.8670\tacc=0.6941\t1285.9 examples/second\n",
      "[Step=2900]\tLoss=0.8630\tacc=0.6959\t1450.4 examples/second\n",
      "[Step=2950]\tLoss=0.8583\tacc=0.6986\t1365.9 examples/second\n",
      "[Step=3000]\tLoss=0.8563\tacc=0.6987\t1470.2 examples/second\n",
      "[Step=3050]\tLoss=0.8530\tacc=0.6997\t1292.2 examples/second\n",
      "[Step=3100]\tLoss=0.8504\tacc=0.7007\t1349.0 examples/second\n",
      "Test Loss=1.5891, Test acc=0.5389\n",
      "\n",
      "Epoch: 8\n",
      "[Step=3150]\tLoss=0.7917\tacc=0.7259\t820.0 examples/second\n",
      "[Step=3200]\tLoss=0.7855\tacc=0.7246\t1414.6 examples/second\n",
      "[Step=3250]\tLoss=0.7879\tacc=0.7239\t1348.1 examples/second\n",
      "[Step=3300]\tLoss=0.7852\tacc=0.7241\t1313.1 examples/second\n",
      "[Step=3350]\tLoss=0.7849\tacc=0.7252\t1365.8 examples/second\n",
      "[Step=3400]\tLoss=0.7892\tacc=0.7235\t1393.3 examples/second\n",
      "[Step=3450]\tLoss=0.7877\tacc=0.7237\t1397.6 examples/second\n",
      "[Step=3500]\tLoss=0.7879\tacc=0.7245\t1248.4 examples/second\n",
      "Test Loss=0.8366, Test acc=0.7141\n",
      "Saving...\n",
      "\n",
      "Epoch: 9\n",
      "[Step=3550]\tLoss=0.7693\tacc=0.7321\t904.6 examples/second\n",
      "[Step=3600]\tLoss=0.7683\tacc=0.7347\t1321.1 examples/second\n",
      "[Step=3650]\tLoss=0.7578\tacc=0.7394\t1360.2 examples/second\n",
      "[Step=3700]\tLoss=0.7564\tacc=0.7378\t1384.4 examples/second\n",
      "[Step=3750]\tLoss=0.7525\tacc=0.7388\t1270.1 examples/second\n",
      "[Step=3800]\tLoss=0.7511\tacc=0.7393\t1315.6 examples/second\n",
      "[Step=3850]\tLoss=0.7475\tacc=0.7399\t1390.9 examples/second\n",
      "[Step=3900]\tLoss=0.7484\tacc=0.7404\t1321.6 examples/second\n",
      "Test Loss=0.9508, Test acc=0.6965\n",
      "\n",
      "Epoch: 10\n",
      "[Step=3950]\tLoss=0.7321\tacc=0.7469\t926.5 examples/second\n",
      "[Step=4000]\tLoss=0.7230\tacc=0.7467\t1232.3 examples/second\n",
      "[Step=4050]\tLoss=0.7158\tacc=0.7515\t1357.4 examples/second\n",
      "[Step=4100]\tLoss=0.7146\tacc=0.7519\t1640.4 examples/second\n",
      "[Step=4150]\tLoss=0.7100\tacc=0.7532\t1463.8 examples/second\n",
      "[Step=4200]\tLoss=0.7066\tacc=0.7551\t1406.3 examples/second\n",
      "[Step=4250]\tLoss=0.7079\tacc=0.7549\t1380.8 examples/second\n",
      "[Step=4300]\tLoss=0.7061\tacc=0.7547\t1382.5 examples/second\n",
      "Test Loss=0.8842, Test acc=0.7100\n",
      "\n",
      "Epoch: 11\n",
      "[Step=4350]\tLoss=0.6526\tacc=0.7728\t917.6 examples/second\n",
      "[Step=4400]\tLoss=0.6618\tacc=0.7723\t1395.2 examples/second\n",
      "[Step=4450]\tLoss=0.6713\tacc=0.7700\t1368.2 examples/second\n",
      "[Step=4500]\tLoss=0.6684\tacc=0.7708\t1367.6 examples/second\n",
      "[Step=4550]\tLoss=0.6691\tacc=0.7705\t1368.2 examples/second\n",
      "[Step=4600]\tLoss=0.6662\tacc=0.7713\t1291.3 examples/second\n",
      "[Step=4650]\tLoss=0.6686\tacc=0.7704\t1299.1 examples/second\n",
      "Test Loss=0.9459, Test acc=0.6962\n",
      "\n",
      "Epoch: 12\n",
      "[Step=4700]\tLoss=0.6187\tacc=0.7910\t910.3 examples/second\n",
      "[Step=4750]\tLoss=0.6242\tacc=0.7854\t1333.7 examples/second\n",
      "[Step=4800]\tLoss=0.6292\tacc=0.7856\t1320.3 examples/second\n",
      "[Step=4850]\tLoss=0.6322\tacc=0.7833\t1310.0 examples/second\n",
      "[Step=4900]\tLoss=0.6339\tacc=0.7833\t1469.8 examples/second\n",
      "[Step=4950]\tLoss=0.6336\tacc=0.7829\t1322.5 examples/second\n",
      "[Step=5000]\tLoss=0.6298\tacc=0.7837\t1316.5 examples/second\n",
      "[Step=5050]\tLoss=0.6319\tacc=0.7834\t1245.3 examples/second\n",
      "Test Loss=0.8859, Test acc=0.7261\n",
      "Saving...\n",
      "\n",
      "Epoch: 13\n",
      "[Step=5100]\tLoss=0.6036\tacc=0.7858\t851.7 examples/second\n",
      "[Step=5150]\tLoss=0.6160\tacc=0.7866\t1278.0 examples/second\n",
      "[Step=5200]\tLoss=0.6135\tacc=0.7881\t1269.5 examples/second\n",
      "[Step=5250]\tLoss=0.6115\tacc=0.7889\t1337.8 examples/second\n",
      "[Step=5300]\tLoss=0.6117\tacc=0.7896\t1299.2 examples/second\n",
      "[Step=5350]\tLoss=0.6114\tacc=0.7895\t1298.1 examples/second\n",
      "[Step=5400]\tLoss=0.6081\tacc=0.7909\t1332.5 examples/second\n",
      "[Step=5450]\tLoss=0.6092\tacc=0.7901\t1313.5 examples/second\n",
      "Test Loss=0.8161, Test acc=0.7401\n",
      "Saving...\n",
      "\n",
      "Epoch: 14\n",
      "[Step=5500]\tLoss=0.5719\tacc=0.8002\t847.0 examples/second\n",
      "[Step=5550]\tLoss=0.5734\tacc=0.8015\t1386.9 examples/second\n",
      "[Step=5600]\tLoss=0.5807\tacc=0.7979\t1344.6 examples/second\n",
      "[Step=5650]\tLoss=0.5908\tacc=0.7966\t1440.8 examples/second\n",
      "[Step=5700]\tLoss=0.5867\tacc=0.7977\t1371.6 examples/second\n",
      "[Step=5750]\tLoss=0.5856\tacc=0.7983\t1264.1 examples/second\n",
      "[Step=5800]\tLoss=0.5843\tacc=0.7990\t1447.1 examples/second\n",
      "[Step=5850]\tLoss=0.5859\tacc=0.7991\t1328.9 examples/second\n",
      "Test Loss=0.6558, Test acc=0.7879\n",
      "Saving...\n",
      "\n",
      "Epoch: 15\n",
      "[Step=5900]\tLoss=0.5615\tacc=0.8067\t848.2 examples/second\n",
      "[Step=5950]\tLoss=0.5516\tacc=0.8110\t1401.6 examples/second\n",
      "[Step=6000]\tLoss=0.5528\tacc=0.8102\t1250.3 examples/second\n",
      "[Step=6050]\tLoss=0.5543\tacc=0.8101\t1278.9 examples/second\n",
      "[Step=6100]\tLoss=0.5543\tacc=0.8100\t1368.0 examples/second\n",
      "[Step=6150]\tLoss=0.5545\tacc=0.8102\t1324.6 examples/second\n",
      "[Step=6200]\tLoss=0.5565\tacc=0.8100\t1601.7 examples/second\n",
      "[Step=6250]\tLoss=0.5584\tacc=0.8084\t1240.4 examples/second\n",
      "Test Loss=0.6737, Test acc=0.7770\n",
      "\n",
      "Epoch: 16\n",
      "[Step=6300]\tLoss=0.5176\tacc=0.8178\t839.7 examples/second\n",
      "[Step=6350]\tLoss=0.5326\tacc=0.8183\t1275.1 examples/second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step=6400]\tLoss=0.5344\tacc=0.8182\t1402.4 examples/second\n",
      "[Step=6450]\tLoss=0.5420\tacc=0.8158\t1344.0 examples/second\n",
      "[Step=6500]\tLoss=0.5408\tacc=0.8151\t1274.5 examples/second\n",
      "[Step=6550]\tLoss=0.5430\tacc=0.8151\t1370.9 examples/second\n",
      "[Step=6600]\tLoss=0.5438\tacc=0.8154\t1375.1 examples/second\n",
      "Test Loss=0.8348, Test acc=0.7350\n",
      "\n",
      "Epoch: 17\n",
      "[Step=6650]\tLoss=0.5269\tacc=0.8203\t876.8 examples/second\n",
      "[Step=6700]\tLoss=0.5248\tacc=0.8218\t1355.2 examples/second\n",
      "[Step=6750]\tLoss=0.5244\tacc=0.8211\t1324.0 examples/second\n",
      "[Step=6800]\tLoss=0.5317\tacc=0.8186\t1311.3 examples/second\n",
      "[Step=6850]\tLoss=0.5306\tacc=0.8180\t1269.3 examples/second\n",
      "[Step=6900]\tLoss=0.5317\tacc=0.8161\t1400.9 examples/second\n",
      "[Step=6950]\tLoss=0.5280\tacc=0.8175\t1377.2 examples/second\n",
      "[Step=7000]\tLoss=0.5304\tacc=0.8170\t1356.6 examples/second\n",
      "Test Loss=0.6036, Test acc=0.7968\n",
      "Saving...\n",
      "\n",
      "Epoch: 18\n",
      "[Step=7050]\tLoss=0.4927\tacc=0.8288\t801.7 examples/second\n",
      "[Step=7100]\tLoss=0.4981\tacc=0.8300\t1259.7 examples/second\n",
      "[Step=7150]\tLoss=0.5085\tacc=0.8285\t1383.8 examples/second\n",
      "[Step=7200]\tLoss=0.5135\tacc=0.8250\t1338.1 examples/second\n",
      "[Step=7250]\tLoss=0.5117\tacc=0.8250\t1295.9 examples/second\n",
      "[Step=7300]\tLoss=0.5059\tacc=0.8271\t1325.8 examples/second\n",
      "[Step=7350]\tLoss=0.5102\tacc=0.8258\t1347.3 examples/second\n",
      "[Step=7400]\tLoss=0.5092\tacc=0.8265\t1304.3 examples/second\n",
      "Test Loss=1.0108, Test acc=0.7045\n",
      "\n",
      "Epoch: 19\n",
      "[Step=7450]\tLoss=0.4882\tacc=0.8240\t830.8 examples/second\n",
      "[Step=7500]\tLoss=0.5011\tacc=0.8257\t1471.8 examples/second\n",
      "[Step=7550]\tLoss=0.5060\tacc=0.8256\t1369.9 examples/second\n",
      "[Step=7600]\tLoss=0.5022\tacc=0.8273\t1401.2 examples/second\n",
      "[Step=7650]\tLoss=0.5033\tacc=0.8273\t1342.8 examples/second\n",
      "[Step=7700]\tLoss=0.5033\tacc=0.8278\t1295.9 examples/second\n",
      "[Step=7750]\tLoss=0.5012\tacc=0.8289\t1390.5 examples/second\n",
      "[Step=7800]\tLoss=0.5031\tacc=0.8283\t1240.0 examples/second\n",
      "Test Loss=0.5759, Test acc=0.8081\n",
      "Saving...\n",
      "\n",
      "Epoch: 20\n",
      "[Step=7850]\tLoss=0.4799\tacc=0.8362\t915.9 examples/second\n",
      "[Step=7900]\tLoss=0.4768\tacc=0.8384\t1197.0 examples/second\n",
      "[Step=7950]\tLoss=0.4768\tacc=0.8392\t1296.4 examples/second\n",
      "[Step=8000]\tLoss=0.4814\tacc=0.8378\t1263.8 examples/second\n",
      "[Step=8050]\tLoss=0.4844\tacc=0.8347\t1307.8 examples/second\n",
      "[Step=8100]\tLoss=0.4853\tacc=0.8346\t1329.2 examples/second\n",
      "[Step=8150]\tLoss=0.4878\tacc=0.8331\t1333.0 examples/second\n",
      "[Step=8200]\tLoss=0.4870\tacc=0.8334\t1282.8 examples/second\n",
      "Test Loss=0.5844, Test acc=0.8024\n",
      "\n",
      "Epoch: 21\n",
      "[Step=8250]\tLoss=0.4816\tacc=0.8371\t815.3 examples/second\n",
      "[Step=8300]\tLoss=0.4655\tacc=0.8416\t1302.9 examples/second\n",
      "[Step=8350]\tLoss=0.4665\tacc=0.8387\t1250.7 examples/second\n",
      "[Step=8400]\tLoss=0.4628\tacc=0.8413\t1362.7 examples/second\n",
      "[Step=8450]\tLoss=0.4630\tacc=0.8416\t1223.6 examples/second\n",
      "[Step=8500]\tLoss=0.4701\tacc=0.8390\t1219.7 examples/second\n",
      "[Step=8550]\tLoss=0.4724\tacc=0.8381\t1367.0 examples/second\n",
      "[Step=8600]\tLoss=0.4729\tacc=0.8373\t1246.2 examples/second\n",
      "Test Loss=0.6499, Test acc=0.7942\n",
      "\n",
      "Epoch: 22\n",
      "[Step=8650]\tLoss=0.4434\tacc=0.8477\t871.6 examples/second\n",
      "[Step=8700]\tLoss=0.4474\tacc=0.8451\t1398.7 examples/second\n",
      "[Step=8750]\tLoss=0.4508\tacc=0.8464\t1266.4 examples/second\n",
      "[Step=8800]\tLoss=0.4568\tacc=0.8449\t1437.6 examples/second\n",
      "[Step=8850]\tLoss=0.4569\tacc=0.8453\t1476.0 examples/second\n",
      "[Step=8900]\tLoss=0.4589\tacc=0.8446\t1223.5 examples/second\n",
      "[Step=8950]\tLoss=0.4619\tacc=0.8430\t1324.5 examples/second\n",
      "Test Loss=0.6013, Test acc=0.8036\n",
      "\n",
      "Epoch: 23\n",
      "[Step=9000]\tLoss=0.4569\tacc=0.8426\t888.7 examples/second\n",
      "[Step=9050]\tLoss=0.4406\tacc=0.8448\t1235.5 examples/second\n",
      "[Step=9100]\tLoss=0.4453\tacc=0.8462\t1353.3 examples/second\n",
      "[Step=9150]\tLoss=0.4406\tacc=0.8489\t1282.1 examples/second\n",
      "[Step=9200]\tLoss=0.4462\tacc=0.8465\t1337.3 examples/second\n",
      "[Step=9250]\tLoss=0.4501\tacc=0.8454\t1300.2 examples/second\n",
      "[Step=9300]\tLoss=0.4539\tacc=0.8441\t1349.3 examples/second\n",
      "[Step=9350]\tLoss=0.4549\tacc=0.8439\t1207.2 examples/second\n",
      "Test Loss=0.6545, Test acc=0.7892\n",
      "\n",
      "Epoch: 24\n",
      "[Step=9400]\tLoss=0.4601\tacc=0.8442\t937.1 examples/second\n",
      "[Step=9450]\tLoss=0.4533\tacc=0.8461\t1211.7 examples/second\n",
      "[Step=9500]\tLoss=0.4442\tacc=0.8494\t1355.2 examples/second\n",
      "[Step=9550]\tLoss=0.4457\tacc=0.8476\t1267.7 examples/second\n",
      "[Step=9600]\tLoss=0.4414\tacc=0.8490\t1320.8 examples/second\n",
      "[Step=9650]\tLoss=0.4484\tacc=0.8461\t1333.0 examples/second\n",
      "[Step=9700]\tLoss=0.4466\tacc=0.8470\t1301.3 examples/second\n",
      "[Step=9750]\tLoss=0.4486\tacc=0.8460\t1321.9 examples/second\n",
      "Test Loss=0.9032, Test acc=0.7447\n",
      "\n",
      "Epoch: 25\n",
      "[Step=9800]\tLoss=0.4405\tacc=0.8497\t895.4 examples/second\n",
      "[Step=9850]\tLoss=0.4366\tacc=0.8507\t1236.3 examples/second\n",
      "[Step=9900]\tLoss=0.4296\tacc=0.8521\t1343.5 examples/second\n",
      "[Step=9950]\tLoss=0.4333\tacc=0.8503\t1323.6 examples/second\n",
      "[Step=10000]\tLoss=0.4395\tacc=0.8496\t1512.7 examples/second\n",
      "[Step=10050]\tLoss=0.4382\tacc=0.8504\t1366.4 examples/second\n",
      "[Step=10100]\tLoss=0.4379\tacc=0.8498\t1129.6 examples/second\n",
      "[Step=10150]\tLoss=0.4390\tacc=0.8494\t1264.8 examples/second\n",
      "Test Loss=0.6462, Test acc=0.7936\n",
      "\n",
      "Epoch: 26\n",
      "[Step=10200]\tLoss=0.4299\tacc=0.8568\t910.9 examples/second\n",
      "[Step=10250]\tLoss=0.4231\tacc=0.8576\t1321.7 examples/second\n",
      "[Step=10300]\tLoss=0.4294\tacc=0.8541\t1240.1 examples/second\n",
      "[Step=10350]\tLoss=0.4335\tacc=0.8520\t1353.7 examples/second\n",
      "[Step=10400]\tLoss=0.4310\tacc=0.8529\t1495.0 examples/second\n",
      "[Step=10450]\tLoss=0.4334\tacc=0.8523\t1291.0 examples/second\n",
      "[Step=10500]\tLoss=0.4335\tacc=0.8520\t1436.7 examples/second\n",
      "[Step=10550]\tLoss=0.4309\tacc=0.8524\t1439.5 examples/second\n",
      "Test Loss=0.6649, Test acc=0.7990\n",
      "\n",
      "Epoch: 27\n",
      "[Step=10600]\tLoss=0.4113\tacc=0.8585\t864.8 examples/second\n",
      "[Step=10650]\tLoss=0.4169\tacc=0.8592\t1408.0 examples/second\n",
      "[Step=10700]\tLoss=0.4126\tacc=0.8604\t1241.9 examples/second\n",
      "[Step=10750]\tLoss=0.4132\tacc=0.8590\t1201.8 examples/second\n",
      "[Step=10800]\tLoss=0.4132\tacc=0.8599\t1369.2 examples/second\n",
      "[Step=10850]\tLoss=0.4165\tacc=0.8578\t1365.4 examples/second\n",
      "[Step=10900]\tLoss=0.4195\tacc=0.8568\t1506.2 examples/second\n",
      "Test Loss=0.6203, Test acc=0.8086\n",
      "Saving...\n",
      "\n",
      "Epoch: 28\n",
      "[Step=10950]\tLoss=0.4601\tacc=0.8359\t892.3 examples/second\n",
      "[Step=11000]\tLoss=0.4236\tacc=0.8594\t1308.6 examples/second\n",
      "[Step=11050]\tLoss=0.4155\tacc=0.8608\t1305.7 examples/second\n",
      "[Step=11100]\tLoss=0.4176\tacc=0.8593\t1270.3 examples/second\n",
      "[Step=11150]\tLoss=0.4126\tacc=0.8611\t1332.2 examples/second\n",
      "[Step=11200]\tLoss=0.4117\tacc=0.8617\t1345.5 examples/second\n",
      "[Step=11250]\tLoss=0.4152\tacc=0.8603\t1295.2 examples/second\n",
      "[Step=11300]\tLoss=0.4181\tacc=0.8583\t1239.6 examples/second\n",
      "Test Loss=0.5947, Test acc=0.8105\n",
      "Saving...\n",
      "\n",
      "Epoch: 29\n",
      "[Step=11350]\tLoss=0.3919\tacc=0.8615\t881.7 examples/second\n",
      "[Step=11400]\tLoss=0.3785\tacc=0.8710\t1285.4 examples/second\n",
      "[Step=11450]\tLoss=0.3925\tacc=0.8655\t1369.1 examples/second\n",
      "[Step=11500]\tLoss=0.4002\tacc=0.8630\t1494.8 examples/second\n",
      "[Step=11550]\tLoss=0.4019\tacc=0.8627\t1319.0 examples/second\n",
      "[Step=11600]\tLoss=0.4028\tacc=0.8617\t1380.1 examples/second\n",
      "[Step=11650]\tLoss=0.4066\tacc=0.8605\t1548.2 examples/second\n",
      "[Step=11700]\tLoss=0.4056\tacc=0.8614\t1349.5 examples/second\n",
      "Test Loss=0.5258, Test acc=0.8278\n",
      "Saving...\n",
      "\n",
      "Epoch: 30\n",
      "[Step=11750]\tLoss=0.3698\tacc=0.8703\t904.0 examples/second\n",
      "[Step=11800]\tLoss=0.3948\tacc=0.8626\t1276.7 examples/second\n",
      "[Step=11850]\tLoss=0.3929\tacc=0.8650\t1262.9 examples/second\n",
      "[Step=11900]\tLoss=0.3941\tacc=0.8640\t1233.5 examples/second\n",
      "[Step=11950]\tLoss=0.4003\tacc=0.8622\t1261.0 examples/second\n",
      "[Step=12000]\tLoss=0.4008\tacc=0.8622\t1259.4 examples/second\n",
      "[Step=12050]\tLoss=0.4005\tacc=0.8623\t1195.9 examples/second\n",
      "[Step=12100]\tLoss=0.4033\tacc=0.8610\t1334.1 examples/second\n",
      "Test Loss=0.5940, Test acc=0.8183\n",
      "\n",
      "Epoch: 31\n",
      "[Step=12150]\tLoss=0.3838\tacc=0.8691\t895.2 examples/second\n",
      "[Step=12200]\tLoss=0.3945\tacc=0.8636\t1267.0 examples/second\n",
      "[Step=12250]\tLoss=0.3961\tacc=0.8646\t1318.6 examples/second\n",
      "[Step=12300]\tLoss=0.4003\tacc=0.8626\t1318.3 examples/second\n",
      "[Step=12350]\tLoss=0.4004\tacc=0.8622\t1320.1 examples/second\n",
      "[Step=12400]\tLoss=0.4028\tacc=0.8614\t1301.4 examples/second\n",
      "[Step=12450]\tLoss=0.4035\tacc=0.8612\t1406.1 examples/second\n",
      "[Step=12500]\tLoss=0.4020\tacc=0.8614\t1313.5 examples/second\n",
      "Test Loss=0.5270, Test acc=0.8324\n",
      "Saving...\n",
      "\n",
      "Epoch: 32\n",
      "[Step=12550]\tLoss=0.3661\tacc=0.8707\t852.7 examples/second\n",
      "[Step=12600]\tLoss=0.3742\tacc=0.8703\t1405.4 examples/second\n",
      "[Step=12650]\tLoss=0.3914\tacc=0.8665\t1323.8 examples/second\n",
      "[Step=12700]\tLoss=0.3913\tacc=0.8663\t1295.2 examples/second\n",
      "[Step=12750]\tLoss=0.3938\tacc=0.8647\t1250.9 examples/second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step=12800]\tLoss=0.3936\tacc=0.8639\t1279.0 examples/second\n",
      "[Step=12850]\tLoss=0.3973\tacc=0.8629\t1422.5 examples/second\n",
      "[Step=12900]\tLoss=0.3957\tacc=0.8632\t1424.2 examples/second\n",
      "Test Loss=0.4487, Test acc=0.8521\n",
      "Saving...\n",
      "\n",
      "Epoch: 33\n",
      "[Step=12950]\tLoss=0.3788\tacc=0.8675\t906.2 examples/second\n",
      "[Step=13000]\tLoss=0.3701\tacc=0.8716\t1357.2 examples/second\n",
      "[Step=13050]\tLoss=0.3751\tacc=0.8710\t1230.3 examples/second\n",
      "[Step=13100]\tLoss=0.3791\tacc=0.8691\t1224.4 examples/second\n",
      "[Step=13150]\tLoss=0.3808\tacc=0.8691\t1206.6 examples/second\n",
      "[Step=13200]\tLoss=0.3823\tacc=0.8683\t1489.0 examples/second\n",
      "[Step=13250]\tLoss=0.3831\tacc=0.8686\t1394.3 examples/second\n",
      "Test Loss=0.5781, Test acc=0.8201\n",
      "\n",
      "Epoch: 34\n",
      "[Step=13300]\tLoss=0.3584\tacc=0.8776\t864.5 examples/second\n",
      "[Step=13350]\tLoss=0.3654\tacc=0.8707\t1315.5 examples/second\n",
      "[Step=13400]\tLoss=0.3680\tacc=0.8717\t1294.2 examples/second\n",
      "[Step=13450]\tLoss=0.3648\tacc=0.8734\t1387.0 examples/second\n",
      "[Step=13500]\tLoss=0.3709\tacc=0.8715\t1406.0 examples/second\n",
      "[Step=13550]\tLoss=0.3754\tacc=0.8709\t1389.6 examples/second\n",
      "[Step=13600]\tLoss=0.3801\tacc=0.8698\t1261.3 examples/second\n",
      "[Step=13650]\tLoss=0.3835\tacc=0.8685\t1296.7 examples/second\n",
      "Test Loss=0.6165, Test acc=0.8097\n",
      "\n",
      "Epoch: 35\n",
      "[Step=13700]\tLoss=0.3584\tacc=0.8776\t848.6 examples/second\n",
      "[Step=13750]\tLoss=0.3763\tacc=0.8696\t1347.2 examples/second\n",
      "[Step=13800]\tLoss=0.3706\tacc=0.8732\t1171.2 examples/second\n",
      "[Step=13850]\tLoss=0.3700\tacc=0.8732\t1198.3 examples/second\n",
      "[Step=13900]\tLoss=0.3690\tacc=0.8735\t1174.6 examples/second\n",
      "[Step=13950]\tLoss=0.3698\tacc=0.8731\t1203.0 examples/second\n",
      "[Step=14000]\tLoss=0.3706\tacc=0.8727\t1188.3 examples/second\n",
      "[Step=14050]\tLoss=0.3703\tacc=0.8731\t1192.4 examples/second\n",
      "Test Loss=0.5291, Test acc=0.8328\n",
      "\n",
      "Epoch: 36\n",
      "[Step=14100]\tLoss=0.3471\tacc=0.8854\t873.2 examples/second\n",
      "[Step=14150]\tLoss=0.3668\tacc=0.8758\t1154.8 examples/second\n",
      "[Step=14200]\tLoss=0.3699\tacc=0.8746\t1222.4 examples/second\n",
      "[Step=14250]\tLoss=0.3655\tacc=0.8745\t1238.8 examples/second\n",
      "[Step=14300]\tLoss=0.3635\tacc=0.8757\t1260.7 examples/second\n",
      "[Step=14350]\tLoss=0.3675\tacc=0.8739\t1320.4 examples/second\n",
      "[Step=14400]\tLoss=0.3721\tacc=0.8723\t1213.6 examples/second\n",
      "[Step=14450]\tLoss=0.3777\tacc=0.8705\t1181.6 examples/second\n",
      "Test Loss=0.6838, Test acc=0.7957\n",
      "\n",
      "Epoch: 37\n",
      "[Step=14500]\tLoss=0.3665\tacc=0.8767\t779.3 examples/second\n",
      "[Step=14550]\tLoss=0.3678\tacc=0.8760\t1184.3 examples/second\n",
      "[Step=14600]\tLoss=0.3658\tacc=0.8763\t1211.0 examples/second\n",
      "[Step=14650]\tLoss=0.3711\tacc=0.8744\t1218.0 examples/second\n",
      "[Step=14700]\tLoss=0.3684\tacc=0.8752\t1188.7 examples/second\n",
      "[Step=14750]\tLoss=0.3698\tacc=0.8739\t1276.0 examples/second\n",
      "[Step=14800]\tLoss=0.3693\tacc=0.8746\t1214.6 examples/second\n",
      "[Step=14850]\tLoss=0.3672\tacc=0.8748\t1242.4 examples/second\n",
      "Test Loss=0.6866, Test acc=0.7915\n",
      "\n",
      "Epoch: 38\n",
      "[Step=14900]\tLoss=0.3422\tacc=0.8789\t870.3 examples/second\n",
      "[Step=14950]\tLoss=0.3565\tacc=0.8747\t1223.7 examples/second\n",
      "[Step=15000]\tLoss=0.3617\tacc=0.8731\t1256.4 examples/second\n",
      "[Step=15050]\tLoss=0.3637\tacc=0.8732\t1332.7 examples/second\n",
      "[Step=15100]\tLoss=0.3616\tacc=0.8756\t1331.1 examples/second\n",
      "[Step=15150]\tLoss=0.3619\tacc=0.8760\t1372.4 examples/second\n",
      "[Step=15200]\tLoss=0.3656\tacc=0.8749\t1323.5 examples/second\n",
      "Test Loss=0.5629, Test acc=0.8216\n",
      "\n",
      "Epoch: 39\n",
      "[Step=15250]\tLoss=0.3538\tacc=0.8828\t801.4 examples/second\n",
      "[Step=15300]\tLoss=0.3447\tacc=0.8770\t1211.7 examples/second\n",
      "[Step=15350]\tLoss=0.3488\tacc=0.8774\t1243.7 examples/second\n",
      "[Step=15400]\tLoss=0.3541\tacc=0.8765\t1214.9 examples/second\n",
      "[Step=15450]\tLoss=0.3513\tacc=0.8778\t1240.8 examples/second\n",
      "[Step=15500]\tLoss=0.3590\tacc=0.8762\t1270.6 examples/second\n",
      "[Step=15550]\tLoss=0.3584\tacc=0.8768\t1288.1 examples/second\n",
      "[Step=15600]\tLoss=0.3574\tacc=0.8771\t1350.3 examples/second\n",
      "Test Loss=0.6058, Test acc=0.8098\n",
      "\n",
      "Epoch: 40\n",
      "[Step=15650]\tLoss=0.3660\tacc=0.8758\t862.4 examples/second\n",
      "[Step=15700]\tLoss=0.3458\tacc=0.8775\t1289.8 examples/second\n",
      "[Step=15750]\tLoss=0.3451\tacc=0.8793\t1272.2 examples/second\n",
      "[Step=15800]\tLoss=0.3460\tacc=0.8803\t1297.5 examples/second\n",
      "[Step=15850]\tLoss=0.3475\tacc=0.8798\t1301.8 examples/second\n",
      "[Step=15900]\tLoss=0.3518\tacc=0.8780\t1237.7 examples/second\n",
      "[Step=15950]\tLoss=0.3548\tacc=0.8773\t1235.6 examples/second\n",
      "[Step=16000]\tLoss=0.3532\tacc=0.8780\t1221.9 examples/second\n",
      "Test Loss=0.5820, Test acc=0.8267\n",
      "\n",
      "Epoch: 41\n",
      "[Step=16050]\tLoss=0.3353\tacc=0.8861\t854.8 examples/second\n",
      "[Step=16100]\tLoss=0.3506\tacc=0.8817\t1307.7 examples/second\n",
      "[Step=16150]\tLoss=0.3533\tacc=0.8797\t1264.0 examples/second\n",
      "[Step=16200]\tLoss=0.3518\tacc=0.8799\t1291.5 examples/second\n",
      "[Step=16250]\tLoss=0.3596\tacc=0.8769\t1276.0 examples/second\n",
      "[Step=16300]\tLoss=0.3589\tacc=0.8773\t1236.9 examples/second\n",
      "[Step=16350]\tLoss=0.3584\tacc=0.8769\t1386.9 examples/second\n",
      "[Step=16400]\tLoss=0.3600\tacc=0.8771\t1316.3 examples/second\n",
      "Test Loss=0.5333, Test acc=0.8293\n",
      "\n",
      "Epoch: 42\n",
      "[Step=16450]\tLoss=0.3362\tacc=0.8828\t870.8 examples/second\n",
      "[Step=16500]\tLoss=0.3478\tacc=0.8799\t1286.3 examples/second\n",
      "[Step=16550]\tLoss=0.3474\tacc=0.8799\t1220.0 examples/second\n",
      "[Step=16600]\tLoss=0.3464\tacc=0.8807\t1315.2 examples/second\n",
      "[Step=16650]\tLoss=0.3446\tacc=0.8820\t1357.5 examples/second\n",
      "[Step=16700]\tLoss=0.3447\tacc=0.8810\t1303.2 examples/second\n",
      "[Step=16750]\tLoss=0.3493\tacc=0.8793\t1296.7 examples/second\n",
      "[Step=16800]\tLoss=0.3528\tacc=0.8785\t1205.1 examples/second\n",
      "Test Loss=0.6180, Test acc=0.8162\n",
      "\n",
      "Epoch: 43\n",
      "[Step=16850]\tLoss=0.3420\tacc=0.8803\t840.6 examples/second\n",
      "[Step=16900]\tLoss=0.3293\tacc=0.8836\t1291.1 examples/second\n",
      "[Step=16950]\tLoss=0.3397\tacc=0.8813\t1280.8 examples/second\n",
      "[Step=17000]\tLoss=0.3413\tacc=0.8806\t1308.4 examples/second\n",
      "[Step=17050]\tLoss=0.3437\tacc=0.8808\t1319.1 examples/second\n",
      "[Step=17100]\tLoss=0.3428\tacc=0.8808\t1237.3 examples/second\n",
      "[Step=17150]\tLoss=0.3436\tacc=0.8807\t1224.6 examples/second\n",
      "[Step=17200]\tLoss=0.3438\tacc=0.8810\t1332.8 examples/second\n",
      "Test Loss=0.6689, Test acc=0.7985\n",
      "\n",
      "Epoch: 44\n",
      "[Step=17250]\tLoss=0.3108\tacc=0.8961\t823.1 examples/second\n",
      "[Step=17300]\tLoss=0.3270\tacc=0.8887\t1260.0 examples/second\n",
      "[Step=17350]\tLoss=0.3351\tacc=0.8837\t1254.2 examples/second\n",
      "[Step=17400]\tLoss=0.3410\tacc=0.8817\t1273.3 examples/second\n",
      "[Step=17450]\tLoss=0.3450\tacc=0.8800\t1288.4 examples/second\n",
      "[Step=17500]\tLoss=0.3442\tacc=0.8804\t1273.2 examples/second\n",
      "[Step=17550]\tLoss=0.3467\tacc=0.8800\t1265.3 examples/second\n",
      "Test Loss=0.6415, Test acc=0.8063\n",
      "\n",
      "Epoch: 45\n",
      "[Step=17600]\tLoss=0.3086\tacc=0.8891\t876.7 examples/second\n",
      "[Step=17650]\tLoss=0.3218\tacc=0.8864\t1237.1 examples/second\n",
      "[Step=17700]\tLoss=0.3288\tacc=0.8850\t1201.8 examples/second\n",
      "[Step=17750]\tLoss=0.3321\tacc=0.8842\t1230.1 examples/second\n",
      "[Step=17800]\tLoss=0.3335\tacc=0.8843\t1231.0 examples/second\n",
      "[Step=17850]\tLoss=0.3348\tacc=0.8841\t1282.5 examples/second\n",
      "[Step=17900]\tLoss=0.3343\tacc=0.8844\t1267.2 examples/second\n",
      "[Step=17950]\tLoss=0.3361\tacc=0.8840\t1190.6 examples/second\n",
      "Test Loss=0.5051, Test acc=0.8383\n",
      "\n",
      "Epoch: 46\n",
      "[Step=18000]\tLoss=0.3060\tacc=0.8951\t834.0 examples/second\n",
      "[Step=18050]\tLoss=0.3222\tacc=0.8895\t1327.4 examples/second\n",
      "[Step=18100]\tLoss=0.3246\tacc=0.8877\t1224.8 examples/second\n",
      "[Step=18150]\tLoss=0.3293\tacc=0.8871\t1273.6 examples/second\n",
      "[Step=18200]\tLoss=0.3315\tacc=0.8863\t1298.0 examples/second\n",
      "[Step=18250]\tLoss=0.3357\tacc=0.8851\t1207.4 examples/second\n",
      "[Step=18300]\tLoss=0.3329\tacc=0.8852\t1216.1 examples/second\n",
      "[Step=18350]\tLoss=0.3330\tacc=0.8854\t1222.8 examples/second\n",
      "Test Loss=0.6578, Test acc=0.7975\n",
      "\n",
      "Epoch: 47\n",
      "[Step=18400]\tLoss=0.3210\tacc=0.8869\t880.4 examples/second\n",
      "[Step=18450]\tLoss=0.3267\tacc=0.8858\t1314.8 examples/second\n",
      "[Step=18500]\tLoss=0.3237\tacc=0.8871\t1288.3 examples/second\n",
      "[Step=18550]\tLoss=0.3288\tacc=0.8874\t1281.1 examples/second\n",
      "[Step=18600]\tLoss=0.3328\tacc=0.8864\t1268.3 examples/second\n",
      "[Step=18650]\tLoss=0.3341\tacc=0.8860\t1211.3 examples/second\n",
      "[Step=18700]\tLoss=0.3340\tacc=0.8851\t1273.3 examples/second\n",
      "[Step=18750]\tLoss=0.3355\tacc=0.8849\t1238.0 examples/second\n",
      "Test Loss=0.6923, Test acc=0.7998\n",
      "\n",
      "Epoch: 48\n",
      "[Step=18800]\tLoss=0.2985\tacc=0.8960\t827.0 examples/second\n",
      "[Step=18850]\tLoss=0.3119\tacc=0.8909\t1272.2 examples/second\n",
      "[Step=18900]\tLoss=0.3199\tacc=0.8887\t1329.2 examples/second\n",
      "[Step=18950]\tLoss=0.3192\tacc=0.8891\t1385.8 examples/second\n",
      "[Step=19000]\tLoss=0.3257\tacc=0.8864\t1338.4 examples/second\n",
      "[Step=19050]\tLoss=0.3302\tacc=0.8859\t1361.5 examples/second\n",
      "[Step=19100]\tLoss=0.3294\tacc=0.8861\t1238.5 examples/second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step=19150]\tLoss=0.3299\tacc=0.8863\t1380.2 examples/second\n",
      "Test Loss=0.5620, Test acc=0.8319\n",
      "\n",
      "Epoch: 49\n",
      "[Step=19200]\tLoss=0.3103\tacc=0.8923\t863.0 examples/second\n",
      "[Step=19250]\tLoss=0.3220\tacc=0.8915\t1329.6 examples/second\n",
      "[Step=19300]\tLoss=0.3237\tacc=0.8907\t1294.9 examples/second\n",
      "[Step=19350]\tLoss=0.3219\tacc=0.8905\t1300.1 examples/second\n",
      "[Step=19400]\tLoss=0.3271\tacc=0.8890\t1238.4 examples/second\n",
      "[Step=19450]\tLoss=0.3327\tacc=0.8866\t1238.1 examples/second\n",
      "[Step=19500]\tLoss=0.3332\tacc=0.8861\t1218.5 examples/second\n",
      "[Step=19550]\tLoss=0.3333\tacc=0.8854\t1257.6 examples/second\n",
      "Test Loss=0.4812, Test acc=0.8501\n",
      "\n",
      "Epoch: 50\n",
      "[Step=19600]\tLoss=0.2642\tacc=0.9103\t891.7 examples/second\n",
      "[Step=19650]\tLoss=0.2543\tacc=0.9144\t1311.3 examples/second\n",
      "[Step=19700]\tLoss=0.2481\tacc=0.9161\t1276.8 examples/second\n",
      "[Step=19750]\tLoss=0.2402\tacc=0.9191\t1422.8 examples/second\n",
      "[Step=19800]\tLoss=0.2362\tacc=0.9203\t1407.2 examples/second\n",
      "[Step=19850]\tLoss=0.2325\tacc=0.9212\t1326.3 examples/second\n",
      "[Step=19900]\tLoss=0.2314\tacc=0.9218\t1277.6 examples/second\n",
      "Test Loss=0.3295, Test acc=0.8907\n",
      "Saving...\n",
      "\n",
      "Epoch: 51\n",
      "[Step=19950]\tLoss=0.2002\tacc=0.9349\t828.3 examples/second\n",
      "[Step=20000]\tLoss=0.1977\tacc=0.9321\t1232.2 examples/second\n",
      "[Step=20050]\tLoss=0.1960\tacc=0.9333\t1288.7 examples/second\n",
      "[Step=20100]\tLoss=0.1996\tacc=0.9321\t1258.8 examples/second\n",
      "[Step=20150]\tLoss=0.1998\tacc=0.9316\t1293.4 examples/second\n",
      "[Step=20200]\tLoss=0.2010\tacc=0.9321\t1226.6 examples/second\n",
      "[Step=20250]\tLoss=0.2007\tacc=0.9322\t1267.5 examples/second\n",
      "[Step=20300]\tLoss=0.1995\tacc=0.9322\t1231.3 examples/second\n",
      "Test Loss=0.3297, Test acc=0.8939\n",
      "Saving...\n",
      "\n",
      "Epoch: 52\n",
      "[Step=20350]\tLoss=0.1843\tacc=0.9362\t812.3 examples/second\n",
      "[Step=20400]\tLoss=0.1799\tacc=0.9375\t1306.4 examples/second\n",
      "[Step=20450]\tLoss=0.1837\tacc=0.9372\t1263.7 examples/second\n",
      "[Step=20500]\tLoss=0.1861\tacc=0.9357\t1236.2 examples/second\n",
      "[Step=20550]\tLoss=0.1860\tacc=0.9358\t1247.5 examples/second\n",
      "[Step=20600]\tLoss=0.1881\tacc=0.9346\t1342.6 examples/second\n",
      "[Step=20650]\tLoss=0.1890\tacc=0.9345\t1428.9 examples/second\n",
      "[Step=20700]\tLoss=0.1897\tacc=0.9341\t1543.4 examples/second\n",
      "Test Loss=0.3270, Test acc=0.8955\n",
      "Saving...\n",
      "\n",
      "Epoch: 53\n",
      "[Step=20750]\tLoss=0.1837\tacc=0.9366\t876.5 examples/second\n",
      "[Step=20800]\tLoss=0.1796\tacc=0.9387\t1274.9 examples/second\n",
      "[Step=20850]\tLoss=0.1780\tacc=0.9385\t1272.6 examples/second\n",
      "[Step=20900]\tLoss=0.1799\tacc=0.9378\t1231.8 examples/second\n",
      "[Step=20950]\tLoss=0.1818\tacc=0.9375\t1426.4 examples/second\n",
      "[Step=21000]\tLoss=0.1817\tacc=0.9377\t1269.6 examples/second\n",
      "[Step=21050]\tLoss=0.1827\tacc=0.9374\t1477.2 examples/second\n",
      "[Step=21100]\tLoss=0.1813\tacc=0.9380\t1323.5 examples/second\n",
      "Test Loss=0.3456, Test acc=0.8914\n",
      "\n",
      "Epoch: 54\n",
      "[Step=21150]\tLoss=0.1720\tacc=0.9418\t834.5 examples/second\n",
      "[Step=21200]\tLoss=0.1733\tacc=0.9422\t1366.1 examples/second\n",
      "[Step=21250]\tLoss=0.1775\tacc=0.9403\t1241.8 examples/second\n",
      "[Step=21300]\tLoss=0.1756\tacc=0.9399\t1264.7 examples/second\n",
      "[Step=21350]\tLoss=0.1746\tacc=0.9404\t1225.8 examples/second\n",
      "[Step=21400]\tLoss=0.1721\tacc=0.9409\t1223.4 examples/second\n",
      "[Step=21450]\tLoss=0.1722\tacc=0.9407\t1200.4 examples/second\n",
      "[Step=21500]\tLoss=0.1711\tacc=0.9411\t1313.5 examples/second\n",
      "Test Loss=0.3433, Test acc=0.8937\n",
      "\n",
      "Epoch: 55\n",
      "[Step=21550]\tLoss=0.1680\tacc=0.9398\t840.5 examples/second\n",
      "[Step=21600]\tLoss=0.1700\tacc=0.9404\t1307.8 examples/second\n",
      "[Step=21650]\tLoss=0.1688\tacc=0.9402\t1264.1 examples/second\n",
      "[Step=21700]\tLoss=0.1716\tacc=0.9393\t1340.6 examples/second\n",
      "[Step=21750]\tLoss=0.1722\tacc=0.9393\t1242.8 examples/second\n",
      "[Step=21800]\tLoss=0.1710\tacc=0.9402\t1292.1 examples/second\n",
      "[Step=21850]\tLoss=0.1697\tacc=0.9411\t1271.0 examples/second\n",
      "Test Loss=0.3499, Test acc=0.8926\n",
      "\n",
      "Epoch: 56\n",
      "[Step=21900]\tLoss=0.1731\tacc=0.9395\t947.7 examples/second\n",
      "[Step=21950]\tLoss=0.1547\tacc=0.9468\t1381.5 examples/second\n",
      "[Step=22000]\tLoss=0.1593\tacc=0.9432\t1256.9 examples/second\n",
      "[Step=22050]\tLoss=0.1607\tacc=0.9426\t1302.7 examples/second\n",
      "[Step=22100]\tLoss=0.1613\tacc=0.9435\t1354.7 examples/second\n",
      "[Step=22150]\tLoss=0.1623\tacc=0.9425\t1337.2 examples/second\n",
      "[Step=22200]\tLoss=0.1633\tacc=0.9420\t1298.2 examples/second\n",
      "[Step=22250]\tLoss=0.1634\tacc=0.9424\t1284.3 examples/second\n",
      "Test Loss=0.3437, Test acc=0.8943\n",
      "\n",
      "Epoch: 57\n",
      "[Step=22300]\tLoss=0.1704\tacc=0.9399\t932.4 examples/second\n",
      "[Step=22350]\tLoss=0.1592\tacc=0.9454\t1244.8 examples/second\n",
      "[Step=22400]\tLoss=0.1625\tacc=0.9439\t1393.6 examples/second\n",
      "[Step=22450]\tLoss=0.1635\tacc=0.9444\t1308.2 examples/second\n",
      "[Step=22500]\tLoss=0.1633\tacc=0.9448\t1345.1 examples/second\n",
      "[Step=22550]\tLoss=0.1622\tacc=0.9453\t1307.5 examples/second\n",
      "[Step=22600]\tLoss=0.1620\tacc=0.9454\t1273.4 examples/second\n",
      "[Step=22650]\tLoss=0.1621\tacc=0.9448\t1306.9 examples/second\n",
      "Test Loss=0.3620, Test acc=0.8909\n",
      "\n",
      "Epoch: 58\n",
      "[Step=22700]\tLoss=0.1560\tacc=0.9492\t906.6 examples/second\n",
      "[Step=22750]\tLoss=0.1504\tacc=0.9493\t1239.0 examples/second\n",
      "[Step=22800]\tLoss=0.1573\tacc=0.9467\t1318.8 examples/second\n",
      "[Step=22850]\tLoss=0.1577\tacc=0.9451\t1295.0 examples/second\n",
      "[Step=22900]\tLoss=0.1590\tacc=0.9448\t1379.3 examples/second\n",
      "[Step=22950]\tLoss=0.1584\tacc=0.9449\t1236.1 examples/second\n",
      "[Step=23000]\tLoss=0.1586\tacc=0.9451\t1324.1 examples/second\n",
      "[Step=23050]\tLoss=0.1596\tacc=0.9448\t1279.7 examples/second\n",
      "Test Loss=0.3390, Test acc=0.8963\n",
      "Saving...\n",
      "\n",
      "Epoch: 59\n",
      "[Step=23100]\tLoss=0.1619\tacc=0.9428\t906.8 examples/second\n",
      "[Step=23150]\tLoss=0.1522\tacc=0.9473\t1287.1 examples/second\n",
      "[Step=23200]\tLoss=0.1506\tacc=0.9483\t1273.0 examples/second\n",
      "[Step=23250]\tLoss=0.1511\tacc=0.9477\t1219.8 examples/second\n",
      "[Step=23300]\tLoss=0.1505\tacc=0.9483\t1278.7 examples/second\n",
      "[Step=23350]\tLoss=0.1529\tacc=0.9468\t1261.7 examples/second\n",
      "[Step=23400]\tLoss=0.1530\tacc=0.9464\t1332.0 examples/second\n",
      "[Step=23450]\tLoss=0.1556\tacc=0.9454\t1316.0 examples/second\n",
      "Test Loss=0.3480, Test acc=0.8960\n",
      "\n",
      "Epoch: 60\n",
      "[Step=23500]\tLoss=0.1524\tacc=0.9484\t860.2 examples/second\n",
      "[Step=23550]\tLoss=0.1488\tacc=0.9498\t1262.5 examples/second\n",
      "[Step=23600]\tLoss=0.1488\tacc=0.9491\t1223.1 examples/second\n",
      "[Step=23650]\tLoss=0.1479\tacc=0.9495\t1316.6 examples/second\n",
      "[Step=23700]\tLoss=0.1495\tacc=0.9485\t1320.3 examples/second\n",
      "[Step=23750]\tLoss=0.1516\tacc=0.9477\t1307.6 examples/second\n",
      "[Step=23800]\tLoss=0.1515\tacc=0.9477\t1319.2 examples/second\n",
      "[Step=23850]\tLoss=0.1523\tacc=0.9476\t1300.7 examples/second\n",
      "Test Loss=0.3493, Test acc=0.8967\n",
      "Saving...\n",
      "\n",
      "Epoch: 61\n",
      "[Step=23900]\tLoss=0.1528\tacc=0.9455\t862.0 examples/second\n",
      "[Step=23950]\tLoss=0.1483\tacc=0.9484\t1374.5 examples/second\n",
      "[Step=24000]\tLoss=0.1439\tacc=0.9500\t1386.4 examples/second\n",
      "[Step=24050]\tLoss=0.1451\tacc=0.9495\t1294.1 examples/second\n",
      "[Step=24100]\tLoss=0.1436\tacc=0.9505\t1275.4 examples/second\n",
      "[Step=24150]\tLoss=0.1470\tacc=0.9492\t1270.6 examples/second\n",
      "[Step=24200]\tLoss=0.1478\tacc=0.9492\t1422.8 examples/second\n",
      "Test Loss=0.3422, Test acc=0.8989\n",
      "Saving...\n",
      "\n",
      "Epoch: 62\n",
      "[Step=24250]\tLoss=0.1581\tacc=0.9473\t856.8 examples/second\n",
      "[Step=24300]\tLoss=0.1599\tacc=0.9426\t1256.2 examples/second\n",
      "[Step=24350]\tLoss=0.1512\tacc=0.9472\t1250.8 examples/second\n",
      "[Step=24400]\tLoss=0.1504\tacc=0.9474\t1285.8 examples/second\n",
      "[Step=24450]\tLoss=0.1492\tacc=0.9481\t1302.1 examples/second\n",
      "[Step=24500]\tLoss=0.1479\tacc=0.9483\t1244.3 examples/second\n",
      "[Step=24550]\tLoss=0.1480\tacc=0.9483\t1323.3 examples/second\n",
      "[Step=24600]\tLoss=0.1498\tacc=0.9481\t1195.6 examples/second\n",
      "Test Loss=0.3473, Test acc=0.8963\n",
      "\n",
      "Epoch: 63\n",
      "[Step=24650]\tLoss=0.1223\tacc=0.9605\t959.2 examples/second\n",
      "[Step=24700]\tLoss=0.1328\tacc=0.9544\t1353.6 examples/second\n",
      "[Step=24750]\tLoss=0.1355\tacc=0.9545\t1238.0 examples/second\n",
      "[Step=24800]\tLoss=0.1387\tacc=0.9527\t1357.7 examples/second\n",
      "[Step=24850]\tLoss=0.1401\tacc=0.9511\t1339.5 examples/second\n",
      "[Step=24900]\tLoss=0.1417\tacc=0.9506\t1322.1 examples/second\n",
      "[Step=24950]\tLoss=0.1420\tacc=0.9504\t1182.8 examples/second\n",
      "[Step=25000]\tLoss=0.1430\tacc=0.9500\t1271.4 examples/second\n",
      "Test Loss=0.3659, Test acc=0.8939\n",
      "\n",
      "Epoch: 64\n",
      "[Step=25050]\tLoss=0.1397\tacc=0.9534\t897.8 examples/second\n",
      "[Step=25100]\tLoss=0.1438\tacc=0.9508\t1301.0 examples/second\n",
      "[Step=25150]\tLoss=0.1401\tacc=0.9521\t1262.3 examples/second\n",
      "[Step=25200]\tLoss=0.1429\tacc=0.9502\t1298.1 examples/second\n",
      "[Step=25250]\tLoss=0.1426\tacc=0.9505\t1292.3 examples/second\n",
      "[Step=25300]\tLoss=0.1433\tacc=0.9505\t1304.6 examples/second\n",
      "[Step=25350]\tLoss=0.1435\tacc=0.9504\t1303.9 examples/second\n",
      "[Step=25400]\tLoss=0.1446\tacc=0.9499\t1288.4 examples/second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss=0.3538, Test acc=0.8944\n",
      "\n",
      "Epoch: 65\n",
      "[Step=25450]\tLoss=0.1412\tacc=0.9491\t847.4 examples/second\n",
      "[Step=25500]\tLoss=0.1346\tacc=0.9515\t1254.0 examples/second\n",
      "[Step=25550]\tLoss=0.1382\tacc=0.9508\t1313.6 examples/second\n",
      "[Step=25600]\tLoss=0.1379\tacc=0.9511\t1357.8 examples/second\n",
      "[Step=25650]\tLoss=0.1390\tacc=0.9510\t1297.5 examples/second\n",
      "[Step=25700]\tLoss=0.1384\tacc=0.9513\t1330.6 examples/second\n",
      "[Step=25750]\tLoss=0.1377\tacc=0.9511\t1281.0 examples/second\n",
      "[Step=25800]\tLoss=0.1380\tacc=0.9510\t1261.4 examples/second\n",
      "Test Loss=0.3558, Test acc=0.8989\n",
      "\n",
      "Epoch: 66\n",
      "[Step=25850]\tLoss=0.1266\tacc=0.9506\t951.9 examples/second\n",
      "[Step=25900]\tLoss=0.1310\tacc=0.9529\t1294.8 examples/second\n",
      "[Step=25950]\tLoss=0.1333\tacc=0.9530\t1230.7 examples/second\n",
      "[Step=26000]\tLoss=0.1344\tacc=0.9524\t1241.9 examples/second\n",
      "[Step=26050]\tLoss=0.1383\tacc=0.9512\t1254.5 examples/second\n",
      "[Step=26100]\tLoss=0.1365\tacc=0.9517\t1243.9 examples/second\n",
      "[Step=26150]\tLoss=0.1359\tacc=0.9522\t1213.9 examples/second\n",
      "Test Loss=0.3706, Test acc=0.8978\n",
      "\n",
      "Epoch: 67\n",
      "[Step=26200]\tLoss=0.1240\tacc=0.9505\t863.0 examples/second\n",
      "[Step=26250]\tLoss=0.1296\tacc=0.9547\t1249.8 examples/second\n",
      "[Step=26300]\tLoss=0.1321\tacc=0.9531\t1318.0 examples/second\n",
      "[Step=26350]\tLoss=0.1318\tacc=0.9543\t1256.2 examples/second\n",
      "[Step=26400]\tLoss=0.1313\tacc=0.9538\t1308.3 examples/second\n",
      "[Step=26450]\tLoss=0.1325\tacc=0.9534\t1265.4 examples/second\n",
      "[Step=26500]\tLoss=0.1315\tacc=0.9535\t1292.8 examples/second\n",
      "[Step=26550]\tLoss=0.1315\tacc=0.9532\t1264.4 examples/second\n",
      "Test Loss=0.3593, Test acc=0.8945\n",
      "\n",
      "Epoch: 68\n",
      "[Step=26600]\tLoss=0.1206\tacc=0.9622\t823.1 examples/second\n",
      "[Step=26650]\tLoss=0.1204\tacc=0.9598\t1273.6 examples/second\n",
      "[Step=26700]\tLoss=0.1275\tacc=0.9568\t1287.9 examples/second\n",
      "[Step=26750]\tLoss=0.1303\tacc=0.9548\t1266.2 examples/second\n",
      "[Step=26800]\tLoss=0.1289\tacc=0.9557\t1322.1 examples/second\n",
      "[Step=26850]\tLoss=0.1303\tacc=0.9550\t1205.7 examples/second\n",
      "[Step=26900]\tLoss=0.1302\tacc=0.9552\t1404.5 examples/second\n",
      "[Step=26950]\tLoss=0.1304\tacc=0.9550\t1351.1 examples/second\n",
      "Test Loss=0.3765, Test acc=0.8919\n",
      "\n",
      "Epoch: 69\n",
      "[Step=27000]\tLoss=0.1216\tacc=0.9591\t882.8 examples/second\n",
      "[Step=27050]\tLoss=0.1243\tacc=0.9563\t1322.2 examples/second\n",
      "[Step=27100]\tLoss=0.1250\tacc=0.9568\t1252.9 examples/second\n",
      "[Step=27150]\tLoss=0.1256\tacc=0.9569\t1311.2 examples/second\n",
      "[Step=27200]\tLoss=0.1280\tacc=0.9557\t1240.6 examples/second\n",
      "[Step=27250]\tLoss=0.1290\tacc=0.9555\t1267.0 examples/second\n",
      "[Step=27300]\tLoss=0.1298\tacc=0.9551\t1255.6 examples/second\n",
      "[Step=27350]\tLoss=0.1302\tacc=0.9546\t1309.6 examples/second\n",
      "Test Loss=0.3739, Test acc=0.8942\n",
      "\n",
      "Epoch: 70\n",
      "[Step=27400]\tLoss=0.1097\tacc=0.9633\t861.7 examples/second\n",
      "[Step=27450]\tLoss=0.1151\tacc=0.9614\t1317.1 examples/second\n",
      "[Step=27500]\tLoss=0.1183\tacc=0.9586\t1322.5 examples/second\n",
      "[Step=27550]\tLoss=0.1236\tacc=0.9569\t1289.2 examples/second\n",
      "[Step=27600]\tLoss=0.1254\tacc=0.9564\t1270.9 examples/second\n",
      "[Step=27650]\tLoss=0.1266\tacc=0.9556\t1456.5 examples/second\n",
      "[Step=27700]\tLoss=0.1257\tacc=0.9562\t1246.0 examples/second\n",
      "[Step=27750]\tLoss=0.1272\tacc=0.9552\t1397.9 examples/second\n",
      "Test Loss=0.3675, Test acc=0.8974\n",
      "\n",
      "Epoch: 71\n",
      "[Step=27800]\tLoss=0.1257\tacc=0.9573\t848.8 examples/second\n",
      "[Step=27850]\tLoss=0.1326\tacc=0.9541\t1221.0 examples/second\n",
      "[Step=27900]\tLoss=0.1273\tacc=0.9560\t1273.3 examples/second\n",
      "[Step=27950]\tLoss=0.1285\tacc=0.9556\t1232.7 examples/second\n",
      "[Step=28000]\tLoss=0.1285\tacc=0.9552\t1224.4 examples/second\n",
      "[Step=28050]\tLoss=0.1288\tacc=0.9552\t1251.7 examples/second\n",
      "[Step=28100]\tLoss=0.1278\tacc=0.9556\t1184.0 examples/second\n",
      "[Step=28150]\tLoss=0.1268\tacc=0.9557\t1160.8 examples/second\n",
      "Test Loss=0.3712, Test acc=0.8966\n",
      "\n",
      "Epoch: 72\n",
      "[Step=28200]\tLoss=0.1208\tacc=0.9616\t865.3 examples/second\n",
      "[Step=28250]\tLoss=0.1244\tacc=0.9576\t1183.1 examples/second\n",
      "[Step=28300]\tLoss=0.1262\tacc=0.9568\t1192.2 examples/second\n",
      "[Step=28350]\tLoss=0.1267\tacc=0.9562\t1206.4 examples/second\n",
      "[Step=28400]\tLoss=0.1269\tacc=0.9563\t1176.8 examples/second\n",
      "[Step=28450]\tLoss=0.1274\tacc=0.9562\t1216.6 examples/second\n",
      "[Step=28500]\tLoss=0.1266\tacc=0.9565\t1198.3 examples/second\n",
      "Test Loss=0.3925, Test acc=0.8935\n",
      "\n",
      "Epoch: 73\n",
      "[Step=28550]\tLoss=0.1190\tacc=0.9554\t828.9 examples/second\n",
      "[Step=28600]\tLoss=0.1192\tacc=0.9609\t1135.6 examples/second\n",
      "[Step=28650]\tLoss=0.1233\tacc=0.9592\t1143.6 examples/second\n",
      "[Step=28700]\tLoss=0.1245\tacc=0.9583\t1177.4 examples/second\n",
      "[Step=28750]\tLoss=0.1239\tacc=0.9586\t1200.9 examples/second\n",
      "[Step=28800]\tLoss=0.1235\tacc=0.9586\t1216.4 examples/second\n",
      "[Step=28850]\tLoss=0.1239\tacc=0.9577\t1229.9 examples/second\n",
      "[Step=28900]\tLoss=0.1219\tacc=0.9580\t1207.9 examples/second\n",
      "Test Loss=0.3727, Test acc=0.8989\n",
      "\n",
      "Epoch: 74\n",
      "[Step=28950]\tLoss=0.1240\tacc=0.9570\t765.4 examples/second\n",
      "[Step=29000]\tLoss=0.1160\tacc=0.9606\t1307.0 examples/second\n",
      "[Step=29050]\tLoss=0.1167\tacc=0.9603\t1165.3 examples/second\n",
      "[Step=29100]\tLoss=0.1208\tacc=0.9580\t1153.8 examples/second\n",
      "[Step=29150]\tLoss=0.1196\tacc=0.9580\t1189.2 examples/second\n",
      "[Step=29200]\tLoss=0.1205\tacc=0.9579\t1172.0 examples/second\n",
      "[Step=29250]\tLoss=0.1220\tacc=0.9575\t1236.9 examples/second\n",
      "[Step=29300]\tLoss=0.1217\tacc=0.9577\t1209.6 examples/second\n",
      "Test Loss=0.3828, Test acc=0.8905\n",
      "\n",
      "Epoch: 75\n",
      "[Step=29350]\tLoss=0.1205\tacc=0.9600\t812.3 examples/second\n",
      "[Step=29400]\tLoss=0.1161\tacc=0.9608\t1132.3 examples/second\n",
      "[Step=29450]\tLoss=0.1147\tacc=0.9614\t1167.4 examples/second\n",
      "[Step=29500]\tLoss=0.1120\tacc=0.9620\t1261.8 examples/second\n",
      "[Step=29550]\tLoss=0.1123\tacc=0.9614\t1298.1 examples/second\n",
      "[Step=29600]\tLoss=0.1127\tacc=0.9611\t1216.5 examples/second\n",
      "[Step=29650]\tLoss=0.1112\tacc=0.9616\t1240.6 examples/second\n",
      "[Step=29700]\tLoss=0.1115\tacc=0.9617\t1199.6 examples/second\n",
      "Test Loss=0.3648, Test acc=0.8980\n",
      "\n",
      "Epoch: 76\n",
      "[Step=29750]\tLoss=0.1041\tacc=0.9662\t812.7 examples/second\n",
      "[Step=29800]\tLoss=0.0975\tacc=0.9688\t1175.6 examples/second\n",
      "[Step=29850]\tLoss=0.0985\tacc=0.9674\t1242.8 examples/second\n",
      "[Step=29900]\tLoss=0.1010\tacc=0.9663\t1212.4 examples/second\n",
      "[Step=29950]\tLoss=0.1026\tacc=0.9651\t1270.1 examples/second\n",
      "[Step=30000]\tLoss=0.1034\tacc=0.9645\t1235.8 examples/second\n",
      "[Step=30050]\tLoss=0.1049\tacc=0.9639\t1232.5 examples/second\n",
      "[Step=30100]\tLoss=0.1051\tacc=0.9639\t1254.1 examples/second\n",
      "Test Loss=0.3593, Test acc=0.8982\n",
      "\n",
      "Epoch: 77\n",
      "[Step=30150]\tLoss=0.1013\tacc=0.9657\t875.3 examples/second\n",
      "[Step=30200]\tLoss=0.1006\tacc=0.9656\t1297.4 examples/second\n",
      "[Step=30250]\tLoss=0.1030\tacc=0.9638\t1337.4 examples/second\n",
      "[Step=30300]\tLoss=0.1025\tacc=0.9643\t1257.3 examples/second\n",
      "[Step=30350]\tLoss=0.1002\tacc=0.9653\t1290.8 examples/second\n",
      "[Step=30400]\tLoss=0.1012\tacc=0.9649\t1336.7 examples/second\n",
      "[Step=30450]\tLoss=0.1030\tacc=0.9643\t1266.6 examples/second\n",
      "Test Loss=0.3632, Test acc=0.8992\n",
      "Saving...\n",
      "\n",
      "Epoch: 78\n",
      "[Step=30500]\tLoss=0.0636\tacc=0.9805\t809.6 examples/second\n",
      "[Step=30550]\tLoss=0.1010\tacc=0.9648\t1335.3 examples/second\n",
      "[Step=30600]\tLoss=0.1032\tacc=0.9649\t1259.5 examples/second\n",
      "[Step=30650]\tLoss=0.1013\tacc=0.9642\t1281.9 examples/second\n",
      "[Step=30700]\tLoss=0.0988\tacc=0.9649\t1221.4 examples/second\n",
      "[Step=30750]\tLoss=0.0983\tacc=0.9651\t1267.5 examples/second\n",
      "[Step=30800]\tLoss=0.0995\tacc=0.9645\t1244.3 examples/second\n",
      "[Step=30850]\tLoss=0.0999\tacc=0.9647\t1217.8 examples/second\n",
      "Test Loss=0.3624, Test acc=0.8989\n",
      "\n",
      "Epoch: 79\n",
      "[Step=30900]\tLoss=0.0907\tacc=0.9730\t824.4 examples/second\n",
      "[Step=30950]\tLoss=0.0936\tacc=0.9695\t1352.9 examples/second\n",
      "[Step=31000]\tLoss=0.0981\tacc=0.9677\t1337.0 examples/second\n",
      "[Step=31050]\tLoss=0.1000\tacc=0.9668\t1379.9 examples/second\n",
      "[Step=31100]\tLoss=0.1000\tacc=0.9664\t1265.5 examples/second\n",
      "[Step=31150]\tLoss=0.0996\tacc=0.9656\t1446.5 examples/second\n",
      "[Step=31200]\tLoss=0.0996\tacc=0.9657\t1218.8 examples/second\n",
      "[Step=31250]\tLoss=0.0992\tacc=0.9658\t1320.7 examples/second\n",
      "Test Loss=0.3636, Test acc=0.8998\n",
      "Saving...\n",
      "\n",
      "Epoch: 80\n",
      "[Step=31300]\tLoss=0.1004\tacc=0.9641\t845.1 examples/second\n",
      "[Step=31350]\tLoss=0.0897\tacc=0.9701\t1448.1 examples/second\n",
      "[Step=31400]\tLoss=0.0940\tacc=0.9684\t1470.8 examples/second\n",
      "[Step=31450]\tLoss=0.0966\tacc=0.9672\t1400.9 examples/second\n",
      "[Step=31500]\tLoss=0.0974\tacc=0.9668\t1294.2 examples/second\n",
      "[Step=31550]\tLoss=0.0979\tacc=0.9667\t1323.2 examples/second\n",
      "[Step=31600]\tLoss=0.0976\tacc=0.9667\t1270.7 examples/second\n",
      "[Step=31650]\tLoss=0.0975\tacc=0.9668\t1210.4 examples/second\n",
      "Test Loss=0.3653, Test acc=0.8987\n",
      "\n",
      "Epoch: 81\n",
      "[Step=31700]\tLoss=0.0931\tacc=0.9679\t822.8 examples/second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step=31750]\tLoss=0.0941\tacc=0.9683\t1293.8 examples/second\n",
      "[Step=31800]\tLoss=0.0927\tacc=0.9687\t1284.0 examples/second\n",
      "[Step=31850]\tLoss=0.0946\tacc=0.9677\t1281.7 examples/second\n",
      "[Step=31900]\tLoss=0.0963\tacc=0.9671\t1307.0 examples/second\n",
      "[Step=31950]\tLoss=0.0993\tacc=0.9660\t1239.8 examples/second\n",
      "[Step=32000]\tLoss=0.0996\tacc=0.9661\t1224.7 examples/second\n",
      "[Step=32050]\tLoss=0.0984\tacc=0.9666\t1257.8 examples/second\n",
      "Test Loss=0.3681, Test acc=0.8993\n",
      "\n",
      "Epoch: 82\n",
      "[Step=32100]\tLoss=0.1018\tacc=0.9653\t875.6 examples/second\n",
      "[Step=32150]\tLoss=0.1006\tacc=0.9664\t1286.7 examples/second\n",
      "[Step=32200]\tLoss=0.1016\tacc=0.9653\t1340.5 examples/second\n",
      "[Step=32250]\tLoss=0.0985\tacc=0.9663\t1258.1 examples/second\n",
      "[Step=32300]\tLoss=0.0999\tacc=0.9657\t1268.2 examples/second\n",
      "[Step=32350]\tLoss=0.0991\tacc=0.9664\t1287.8 examples/second\n",
      "[Step=32400]\tLoss=0.0991\tacc=0.9660\t1166.7 examples/second\n",
      "[Step=32450]\tLoss=0.0983\tacc=0.9663\t1244.5 examples/second\n",
      "Test Loss=0.3682, Test acc=0.8999\n",
      "Saving...\n",
      "\n",
      "Epoch: 83\n",
      "[Step=32500]\tLoss=0.0988\tacc=0.9664\t850.0 examples/second\n",
      "[Step=32550]\tLoss=0.0940\tacc=0.9678\t1204.8 examples/second\n",
      "[Step=32600]\tLoss=0.0949\tacc=0.9677\t1262.1 examples/second\n",
      "[Step=32650]\tLoss=0.0941\tacc=0.9676\t1283.5 examples/second\n",
      "[Step=32700]\tLoss=0.0940\tacc=0.9678\t1258.5 examples/second\n",
      "[Step=32750]\tLoss=0.0941\tacc=0.9680\t1262.7 examples/second\n",
      "[Step=32800]\tLoss=0.0943\tacc=0.9681\t1266.2 examples/second\n",
      "Test Loss=0.3706, Test acc=0.8982\n",
      "\n",
      "Epoch: 84\n",
      "[Step=32850]\tLoss=0.1126\tacc=0.9596\t899.4 examples/second\n",
      "[Step=32900]\tLoss=0.0974\tacc=0.9653\t1305.2 examples/second\n",
      "[Step=32950]\tLoss=0.0951\tacc=0.9679\t1266.0 examples/second\n",
      "[Step=33000]\tLoss=0.0941\tacc=0.9675\t1353.1 examples/second\n",
      "[Step=33050]\tLoss=0.0933\tacc=0.9684\t1311.6 examples/second\n",
      "[Step=33100]\tLoss=0.0941\tacc=0.9679\t1317.5 examples/second\n",
      "[Step=33150]\tLoss=0.0932\tacc=0.9684\t1436.2 examples/second\n",
      "[Step=33200]\tLoss=0.0928\tacc=0.9683\t1360.1 examples/second\n",
      "Test Loss=0.3700, Test acc=0.8984\n",
      "\n",
      "Epoch: 85\n",
      "[Step=33250]\tLoss=0.0900\tacc=0.9708\t847.9 examples/second\n",
      "[Step=33300]\tLoss=0.1044\tacc=0.9659\t1350.9 examples/second\n",
      "[Step=33350]\tLoss=0.0988\tacc=0.9676\t1324.3 examples/second\n",
      "[Step=33400]\tLoss=0.0972\tacc=0.9674\t1332.7 examples/second\n",
      "[Step=33450]\tLoss=0.0976\tacc=0.9672\t1448.1 examples/second\n",
      "[Step=33500]\tLoss=0.0962\tacc=0.9680\t1330.3 examples/second\n",
      "[Step=33550]\tLoss=0.0952\tacc=0.9684\t1384.8 examples/second\n",
      "[Step=33600]\tLoss=0.0945\tacc=0.9683\t1409.8 examples/second\n",
      "Test Loss=0.3697, Test acc=0.8998\n",
      "\n",
      "Epoch: 86\n",
      "[Step=33650]\tLoss=0.0968\tacc=0.9629\t901.1 examples/second\n",
      "[Step=33700]\tLoss=0.0939\tacc=0.9663\t1319.8 examples/second\n",
      "[Step=33750]\tLoss=0.0990\tacc=0.9640\t1431.4 examples/second\n",
      "[Step=33800]\tLoss=0.0965\tacc=0.9658\t1322.9 examples/second\n",
      "[Step=33850]\tLoss=0.0981\tacc=0.9658\t1251.6 examples/second\n",
      "[Step=33900]\tLoss=0.0987\tacc=0.9658\t1344.2 examples/second\n",
      "[Step=33950]\tLoss=0.0975\tacc=0.9663\t1426.9 examples/second\n",
      "[Step=34000]\tLoss=0.0968\tacc=0.9667\t1436.0 examples/second\n",
      "Test Loss=0.3741, Test acc=0.8975\n",
      "\n",
      "Epoch: 87\n",
      "[Step=34050]\tLoss=0.0994\tacc=0.9695\t879.5 examples/second\n",
      "[Step=34100]\tLoss=0.0987\tacc=0.9678\t1396.0 examples/second\n",
      "[Step=34150]\tLoss=0.0957\tacc=0.9680\t1614.5 examples/second\n",
      "[Step=34200]\tLoss=0.0943\tacc=0.9685\t1250.3 examples/second\n",
      "[Step=34250]\tLoss=0.0953\tacc=0.9681\t1298.6 examples/second\n",
      "[Step=34300]\tLoss=0.0954\tacc=0.9681\t1343.1 examples/second\n",
      "[Step=34350]\tLoss=0.0945\tacc=0.9688\t1393.4 examples/second\n",
      "[Step=34400]\tLoss=0.0951\tacc=0.9683\t1263.7 examples/second\n",
      "Test Loss=0.3704, Test acc=0.8989\n",
      "\n",
      "Epoch: 88\n",
      "[Step=34450]\tLoss=0.0919\tacc=0.9686\t812.1 examples/second\n",
      "[Step=34500]\tLoss=0.0969\tacc=0.9677\t1271.4 examples/second\n",
      "[Step=34550]\tLoss=0.0959\tacc=0.9676\t1331.5 examples/second\n",
      "[Step=34600]\tLoss=0.0959\tacc=0.9678\t1427.5 examples/second\n",
      "[Step=34650]\tLoss=0.0970\tacc=0.9669\t1342.1 examples/second\n",
      "[Step=34700]\tLoss=0.0960\tacc=0.9672\t1244.0 examples/second\n",
      "[Step=34750]\tLoss=0.0956\tacc=0.9674\t1344.6 examples/second\n",
      "Test Loss=0.3722, Test acc=0.8990\n",
      "\n",
      "Epoch: 89\n",
      "[Step=34800]\tLoss=0.0423\tacc=0.9922\t844.6 examples/second\n",
      "[Step=34850]\tLoss=0.0806\tacc=0.9732\t1375.9 examples/second\n",
      "[Step=34900]\tLoss=0.0875\tacc=0.9699\t1345.0 examples/second\n",
      "[Step=34950]\tLoss=0.0899\tacc=0.9694\t1309.5 examples/second\n",
      "[Step=35000]\tLoss=0.0922\tacc=0.9684\t1282.9 examples/second\n",
      "[Step=35050]\tLoss=0.0915\tacc=0.9687\t1379.7 examples/second\n",
      "[Step=35100]\tLoss=0.0925\tacc=0.9682\t1451.1 examples/second\n",
      "[Step=35150]\tLoss=0.0946\tacc=0.9674\t1285.6 examples/second\n",
      "Test Loss=0.3778, Test acc=0.8977\n",
      "\n",
      "Epoch: 90\n",
      "[Step=35200]\tLoss=0.0805\tacc=0.9734\t848.7 examples/second\n",
      "[Step=35250]\tLoss=0.0921\tacc=0.9688\t1322.9 examples/second\n",
      "[Step=35300]\tLoss=0.0941\tacc=0.9668\t1375.9 examples/second\n",
      "[Step=35350]\tLoss=0.0954\tacc=0.9668\t1406.7 examples/second\n",
      "[Step=35400]\tLoss=0.0955\tacc=0.9665\t1214.6 examples/second\n",
      "[Step=35450]\tLoss=0.0974\tacc=0.9655\t1285.8 examples/second\n",
      "[Step=35500]\tLoss=0.0968\tacc=0.9657\t1355.6 examples/second\n",
      "[Step=35550]\tLoss=0.0956\tacc=0.9663\t1373.0 examples/second\n",
      "Test Loss=0.3712, Test acc=0.9001\n",
      "Saving...\n",
      "\n",
      "Epoch: 91\n",
      "[Step=35600]\tLoss=0.0827\tacc=0.9712\t848.1 examples/second\n",
      "[Step=35650]\tLoss=0.0933\tacc=0.9667\t1368.5 examples/second\n",
      "[Step=35700]\tLoss=0.0935\tacc=0.9668\t1292.5 examples/second\n",
      "[Step=35750]\tLoss=0.0922\tacc=0.9681\t1279.7 examples/second\n",
      "[Step=35800]\tLoss=0.0944\tacc=0.9673\t1311.9 examples/second\n",
      "[Step=35850]\tLoss=0.0941\tacc=0.9678\t1226.5 examples/second\n",
      "[Step=35900]\tLoss=0.0948\tacc=0.9675\t1202.7 examples/second\n",
      "[Step=35950]\tLoss=0.0946\tacc=0.9676\t1148.5 examples/second\n",
      "Test Loss=0.3737, Test acc=0.9004\n",
      "Saving...\n",
      "\n",
      "Epoch: 92\n",
      "[Step=36000]\tLoss=0.0920\tacc=0.9715\t890.7 examples/second\n",
      "[Step=36050]\tLoss=0.0919\tacc=0.9698\t1273.6 examples/second\n",
      "[Step=36100]\tLoss=0.0913\tacc=0.9689\t1331.6 examples/second\n",
      "[Step=36150]\tLoss=0.0916\tacc=0.9688\t1279.8 examples/second\n",
      "[Step=36200]\tLoss=0.0938\tacc=0.9678\t1291.3 examples/second\n",
      "[Step=36250]\tLoss=0.0933\tacc=0.9681\t1313.8 examples/second\n",
      "[Step=36300]\tLoss=0.0931\tacc=0.9682\t1324.0 examples/second\n",
      "[Step=36350]\tLoss=0.0923\tacc=0.9685\t1393.5 examples/second\n",
      "Test Loss=0.3753, Test acc=0.8981\n",
      "\n",
      "Epoch: 93\n",
      "[Step=36400]\tLoss=0.0888\tacc=0.9700\t894.7 examples/second\n",
      "[Step=36450]\tLoss=0.0868\tacc=0.9706\t1295.4 examples/second\n",
      "[Step=36500]\tLoss=0.0907\tacc=0.9686\t1476.7 examples/second\n",
      "[Step=36550]\tLoss=0.0909\tacc=0.9687\t1417.7 examples/second\n",
      "[Step=36600]\tLoss=0.0913\tacc=0.9687\t1405.9 examples/second\n",
      "[Step=36650]\tLoss=0.0923\tacc=0.9681\t1324.7 examples/second\n",
      "[Step=36700]\tLoss=0.0909\tacc=0.9685\t1512.8 examples/second\n",
      "[Step=36750]\tLoss=0.0920\tacc=0.9683\t1318.5 examples/second\n",
      "Test Loss=0.3837, Test acc=0.8981\n",
      "\n",
      "Epoch: 94\n",
      "[Step=36800]\tLoss=0.0857\tacc=0.9716\t833.1 examples/second\n",
      "[Step=36850]\tLoss=0.0851\tacc=0.9722\t1301.5 examples/second\n",
      "[Step=36900]\tLoss=0.0866\tacc=0.9711\t1376.6 examples/second\n",
      "[Step=36950]\tLoss=0.0867\tacc=0.9710\t1333.5 examples/second\n",
      "[Step=37000]\tLoss=0.0869\tacc=0.9708\t1332.5 examples/second\n",
      "[Step=37050]\tLoss=0.0871\tacc=0.9705\t1293.4 examples/second\n",
      "[Step=37100]\tLoss=0.0882\tacc=0.9705\t1245.6 examples/second\n",
      "Test Loss=0.3802, Test acc=0.8982\n",
      "\n",
      "Epoch: 95\n",
      "[Step=37150]\tLoss=0.0900\tacc=0.9719\t917.6 examples/second\n",
      "[Step=37200]\tLoss=0.0873\tacc=0.9707\t1274.5 examples/second\n",
      "[Step=37250]\tLoss=0.0911\tacc=0.9691\t1293.6 examples/second\n",
      "[Step=37300]\tLoss=0.0903\tacc=0.9695\t1403.3 examples/second\n",
      "[Step=37350]\tLoss=0.0909\tacc=0.9693\t1337.3 examples/second\n",
      "[Step=37400]\tLoss=0.0910\tacc=0.9693\t1293.3 examples/second\n",
      "[Step=37450]\tLoss=0.0912\tacc=0.9688\t1481.5 examples/second\n",
      "[Step=37500]\tLoss=0.0917\tacc=0.9685\t1301.5 examples/second\n",
      "Test Loss=0.3786, Test acc=0.8989\n",
      "\n",
      "Epoch: 96\n",
      "[Step=37550]\tLoss=0.0742\tacc=0.9732\t927.6 examples/second\n",
      "[Step=37600]\tLoss=0.0883\tacc=0.9703\t1346.2 examples/second\n",
      "[Step=37650]\tLoss=0.0878\tacc=0.9705\t1296.8 examples/second\n",
      "[Step=37700]\tLoss=0.0888\tacc=0.9706\t1243.8 examples/second\n",
      "[Step=37750]\tLoss=0.0893\tacc=0.9702\t1520.4 examples/second\n",
      "[Step=37800]\tLoss=0.0889\tacc=0.9702\t1618.0 examples/second\n",
      "[Step=37850]\tLoss=0.0902\tacc=0.9699\t1367.6 examples/second\n",
      "[Step=37900]\tLoss=0.0901\tacc=0.9698\t1334.9 examples/second\n",
      "Test Loss=0.3741, Test acc=0.9000\n",
      "\n",
      "Epoch: 97\n",
      "[Step=37950]\tLoss=0.0859\tacc=0.9704\t851.5 examples/second\n",
      "[Step=38000]\tLoss=0.0857\tacc=0.9701\t1419.0 examples/second\n",
      "[Step=38050]\tLoss=0.0870\tacc=0.9701\t1323.0 examples/second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step=38100]\tLoss=0.0871\tacc=0.9699\t1245.5 examples/second\n",
      "[Step=38150]\tLoss=0.0879\tacc=0.9694\t1395.1 examples/second\n",
      "[Step=38200]\tLoss=0.0873\tacc=0.9702\t1274.8 examples/second\n",
      "[Step=38250]\tLoss=0.0886\tacc=0.9693\t1312.8 examples/second\n",
      "[Step=38300]\tLoss=0.0909\tacc=0.9683\t1288.3 examples/second\n",
      "Test Loss=0.3789, Test acc=0.8981\n",
      "\n",
      "Epoch: 98\n",
      "[Step=38350]\tLoss=0.0926\tacc=0.9700\t877.1 examples/second\n",
      "[Step=38400]\tLoss=0.0925\tacc=0.9684\t1419.5 examples/second\n",
      "[Step=38450]\tLoss=0.0888\tacc=0.9702\t1337.4 examples/second\n",
      "[Step=38500]\tLoss=0.0892\tacc=0.9697\t1244.5 examples/second\n",
      "[Step=38550]\tLoss=0.0902\tacc=0.9698\t1206.5 examples/second\n",
      "[Step=38600]\tLoss=0.0883\tacc=0.9707\t1247.6 examples/second\n",
      "[Step=38650]\tLoss=0.0893\tacc=0.9706\t1198.8 examples/second\n",
      "[Step=38700]\tLoss=0.0898\tacc=0.9700\t1208.6 examples/second\n",
      "Test Loss=0.3800, Test acc=0.8980\n",
      "\n",
      "Epoch: 99\n",
      "[Step=38750]\tLoss=0.0872\tacc=0.9718\t809.4 examples/second\n",
      "[Step=38800]\tLoss=0.0867\tacc=0.9719\t1261.2 examples/second\n",
      "[Step=38850]\tLoss=0.0898\tacc=0.9703\t1370.9 examples/second\n",
      "[Step=38900]\tLoss=0.0902\tacc=0.9701\t1350.9 examples/second\n",
      "[Step=38950]\tLoss=0.0904\tacc=0.9697\t1241.0 examples/second\n",
      "[Step=39000]\tLoss=0.0907\tacc=0.9693\t1235.9 examples/second\n",
      "[Step=39050]\tLoss=0.0907\tacc=0.9696\t1367.4 examples/second\n",
      "[Step=39100]\tLoss=0.0899\tacc=0.9696\t1271.0 examples/second\n",
      "Test Loss=0.3783, Test acc=0.8986\n"
     ]
    }
   ],
   "source": [
    "net = ResNetCIFAR(num_layers=56)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(\"saved_models/resnet_56_base.pt\"))\n",
    "\n",
    "# Comment if you have loaded pretrained weights\n",
    "train_gsm_structured(net, epochs=EPOCHS, batch_size=64, lr=0.005, nonzero_ratio = NON_ZERO_RATIO, \n",
    "                     reg=1e-4, \n",
    "                     net_name = 'resnet_56_struct_gsm_before_pruning.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"saved_models/resnet_56_struct_gsm_before_pruning.pt\"))\n",
    "final_struct_pruning(net, nonzero_ratio = NON_ZERO_RATIO, \n",
    "                     net_name = \"resnet_56_struct_gsm_after_pruning.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Test Loss=0.3678, Test accuracy=0.8996\n",
      "Layer id\tType\t\tParameter\tNon-zero parameter\tSparsity(\\%)\n",
      "1\t\tConvolutional_Param\t864\t\t783\t\t\t0.093750\n",
      "1\t\tConvolutional_Filter\t32\t\t29\t\t\t0.093750\n",
      "2\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "3\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "4\t\tConvolutional_Param\t4608\t\t3744\t\t\t0.187500\n",
      "4\t\tConvolutional_Filter\t16\t\t13\t\t\t0.187500\n",
      "5\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "6\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "7\t\tConvolutional_Param\t2304\t\t2016\t\t\t0.125000\n",
      "7\t\tConvolutional_Filter\t16\t\t14\t\t\t0.125000\n",
      "8\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "9\t\tConvolutional_Param\t512\t\t480\t\t\t0.062500\n",
      "9\t\tConvolutional_Filter\t16\t\t15\t\t\t0.062500\n",
      "10\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "11\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "12\t\tConvolutional_Param\t2304\t\t2160\t\t\t0.062500\n",
      "12\t\tConvolutional_Filter\t16\t\t15\t\t\t0.062500\n",
      "13\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "14\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "15\t\tConvolutional_Param\t2304\t\t2007\t\t\t0.128906\n",
      "15\t\tConvolutional_Filter\t16\t\t14\t\t\t0.125000\n",
      "16\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "17\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "18\t\tConvolutional_Param\t2304\t\t2160\t\t\t0.062500\n",
      "18\t\tConvolutional_Filter\t16\t\t15\t\t\t0.062500\n",
      "19\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "20\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "21\t\tConvolutional_Param\t2304\t\t2016\t\t\t0.125000\n",
      "21\t\tConvolutional_Filter\t16\t\t14\t\t\t0.125000\n",
      "22\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "23\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "24\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "24\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "25\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "26\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "27\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "27\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "28\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "29\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "30\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "30\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "31\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "32\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "33\t\tConvolutional_Param\t2304\t\t2160\t\t\t0.062500\n",
      "33\t\tConvolutional_Filter\t16\t\t15\t\t\t0.062500\n",
      "34\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "35\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "36\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "36\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "37\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "38\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "39\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "39\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "40\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "41\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "42\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "42\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "43\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "44\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "45\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "45\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "46\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "47\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "48\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "48\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "49\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "50\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "51\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "51\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "52\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "53\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "54\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "54\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "55\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "56\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "57\t\tConvolutional_Param\t2304\t\t2304\t\t\t0.000000\n",
      "57\t\tConvolutional_Filter\t16\t\t16\t\t\t0.000000\n",
      "58\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "59\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "60\t\tConvolutional_Param\t4608\t\t4608\t\t\t0.000000\n",
      "60\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "61\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "62\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "63\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "63\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "64\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "65\t\tConvolutional_Param\t512\t\t512\t\t\t0.000000\n",
      "65\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "66\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "67\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "68\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "68\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "69\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "70\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "71\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "71\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "72\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "73\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "74\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "74\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "75\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "76\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "77\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "77\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "78\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "79\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "80\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "80\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "81\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "82\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "83\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "83\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "84\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "85\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "86\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "86\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "87\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "88\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "89\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "89\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "90\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "91\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "92\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "92\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "93\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "94\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "95\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "95\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "96\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "97\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "98\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "98\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "99\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "100\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "101\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "101\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "102\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "103\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "104\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "104\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "105\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "106\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "107\t\tConvolutional_Param\t9216\t\t8928\t\t\t0.031250\n",
      "107\t\tConvolutional_Filter\t32\t\t31\t\t\t0.031250\n",
      "108\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "109\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "110\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "110\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "111\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "112\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "113\t\tConvolutional_Param\t9216\t\t9216\t\t\t0.000000\n",
      "113\t\tConvolutional_Filter\t32\t\t32\t\t\t0.000000\n",
      "114\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "115\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "116\t\tConvolutional_Param\t18432\t\t18432\t\t\t0.000000\n",
      "116\t\tConvolutional_Filter\t64\t\t64\t\t\t0.000000\n",
      "117\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "118\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "119\t\tConvolutional_Param\t36864\t\t5184\t\t\t0.859375\n",
      "119\t\tConvolutional_Filter\t64\t\t9\t\t\t0.859375\n",
      "120\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "121\t\tConvolutional_Param\t2048\t\t288\t\t\t0.859375\n",
      "121\t\tConvolutional_Filter\t64\t\t9\t\t\t0.859375\n",
      "122\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "123\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "124\t\tConvolutional_Param\t36864\t\t1789\t\t\t0.951470\n",
      "124\t\tConvolutional_Filter\t64\t\t12\t\t\t0.812500\n",
      "125\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "126\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "127\t\tConvolutional_Param\t36864\t\t1728\t\t\t0.953125\n",
      "127\t\tConvolutional_Filter\t64\t\t3\t\t\t0.953125\n",
      "128\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "129\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "130\t\tConvolutional_Param\t36864\t\t1053\t\t\t0.971436\n",
      "130\t\tConvolutional_Filter\t64\t\t13\t\t\t0.796875\n",
      "131\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "132\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "133\t\tConvolutional_Param\t36864\t\t1728\t\t\t0.953125\n",
      "133\t\tConvolutional_Filter\t64\t\t3\t\t\t0.953125\n",
      "134\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "135\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "136\t\tConvolutional_Param\t36864\t\t2902\t\t\t0.921278\n",
      "136\t\tConvolutional_Filter\t64\t\t14\t\t\t0.781250\n",
      "137\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "138\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "139\t\tConvolutional_Param\t36864\t\t2880\t\t\t0.921875\n",
      "139\t\tConvolutional_Filter\t64\t\t5\t\t\t0.921875\n",
      "140\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "141\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "142\t\tConvolutional_Param\t36864\t\t1053\t\t\t0.971436\n",
      "142\t\tConvolutional_Filter\t64\t\t13\t\t\t0.796875\n",
      "143\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "144\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "145\t\tConvolutional_Param\t36864\t\t2304\t\t\t0.937500\n",
      "145\t\tConvolutional_Filter\t64\t\t4\t\t\t0.937500\n",
      "146\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "147\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "148\t\tConvolutional_Param\t36864\t\t0\t\t\t1.000000\n",
      "148\t\tConvolutional_Filter\t64\t\t0\t\t\t1.000000\n",
      "149\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "150\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "151\t\tConvolutional_Param\t36864\t\t0\t\t\t1.000000\n",
      "151\t\tConvolutional_Filter\t64\t\t0\t\t\t1.000000\n",
      "152\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "153\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "154\t\tConvolutional_Param\t36864\t\t0\t\t\t1.000000\n",
      "154\t\tConvolutional_Filter\t64\t\t0\t\t\t1.000000\n",
      "155\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "156\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "157\t\tConvolutional_Param\t36864\t\t0\t\t\t1.000000\n",
      "157\t\tConvolutional_Filter\t64\t\t0\t\t\t1.000000\n",
      "158\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "159\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "160\t\tConvolutional_Param\t36864\t\t1053\t\t\t0.971436\n",
      "160\t\tConvolutional_Filter\t64\t\t13\t\t\t0.796875\n",
      "161\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "162\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "163\t\tConvolutional_Param\t36864\t\t1728\t\t\t0.953125\n",
      "163\t\tConvolutional_Filter\t64\t\t3\t\t\t0.953125\n",
      "164\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "165\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "166\t\tConvolutional_Param\t36864\t\t918\t\t\t0.975098\n",
      "166\t\tConvolutional_Filter\t64\t\t9\t\t\t0.859375\n",
      "167\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "168\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "169\t\tConvolutional_Param\t36864\t\t1152\t\t\t0.968750\n",
      "169\t\tConvolutional_Filter\t64\t\t2\t\t\t0.968750\n",
      "170\t\tBatchNorm\tN/A\t\tN/A\t\t\tN/A\n",
      "171\t\tReLU\t\tN/A\t\tN/A\t\t\tN/A\n",
      "172\t\tLinear\t\t640\t\t90\t\t\t0.859375\n",
      "172\t\ttLinear_Filter\t10\t\t10\t\t\t0.000000\n",
      "Total nonzero parameters: 248656\n",
      "Total parameters: 854752\n",
      "Total sparsity: 0.709090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88292762.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"saved_models/resnet_56_struct_gsm_after_pruning.pt\"))\n",
    "test(net)\n",
    "summary(net)\n",
    "compute_conv_flops(net, cuda=True, prune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
